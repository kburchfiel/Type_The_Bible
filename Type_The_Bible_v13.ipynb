{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type Through The Bible\n",
    "\n",
    "By Kenneth Burchfiel\n",
    "\n",
    "*Code is released under the MIT license; Bible verses are from a slightly modified version of the Web English Bible (Catholic Edition)* and are in the public domain.*\n",
    "\n",
    "\\* Genesis was not found within the original WEB Catholic Edition folder, so I copied in files from another Web English Bible translation instead. I imagine, but am not certain, that these files are the same as the actual Catholic Edition's Genesis files. In addition, to make it easier to type verses, I also replaced the em dashes in the original file with double hyphens and replaced curly single and double quotes with straight ones. Finally, I removed the character between the final ' and \" in verse 30502 (John 5:11) because it didn't appear to be a regular space (and a space wasn't needed here anyway)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions for getting started:\n",
    "\n",
    "If you have just downloaded the source code for this game through GitHub, you'll need to make certain updates to the folder directory so that you see your results instead of mine:\n",
    "\n",
    "1. Rename WEB_Catholic_Version_for_game_updated.csv as **WEB_Catholic_Version_for_game_updated_sample.csv**; results.csv as **results_sample.csv**; and word_stats.csv as **word_stats_sample.csv** (if these files are present in the directory).\n",
    "\n",
    "1. Make a copy of **WEB_Catholic_Version_for_game.csv** and rename it **WEB_Catholic_Version_for_game_updated.csv**.\n",
    "\n",
    "1. Delete the Analyses folder (if it already exists).\n",
    "\n",
    "You're now ready to play!\n",
    "\n",
    "Note: If you instead downloaded an executable copy of this game from Itch.io, the above steps aren't necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps for development: (Not necessarily in order of importance)\n",
    "\n",
    "* Add documentation\n",
    "* Create a regression analysis that attempts to use data about the verse (length, number of capital letters, etc.)\n",
    "* Add in a help/disclaimer/credits/dedication section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file shows the source code for Type Through The Bible. I am working to add in documentation to make the code more intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first import a number of libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "import time\n",
    "import plotly.express as px\n",
    "from getch import getch # Installed this library using pip install py-getch, not\n",
    "# pip install getch. See https://github.com/joeyespo/py-getch\n",
    "import numpy as np\n",
    "# import statsmodels as sm\n",
    "from datetime import datetime, date, timezone # Based on \n",
    "# https://docs.python.org/3/library/datetime.html\n",
    "import os\n",
    "from colorama import just_fix_windows_console\n",
    "# From https://github.com/tartley/colorama/blob/master/demos/demo01.py\n",
    "# The following line allows ANSI escape codes to display correctly on Windows.\n",
    "# For more information, see # https://github.com/tartley/colorama .\n",
    "just_fix_windows_console() \n",
    "\n",
    "# Note: You'll also need to have kaleido installed if you set \n",
    "# save_image_copies_of_charts (see below) to True, as it \n",
    "# will get called by Plotly later in the program.\n",
    "# For Windows, I ran conda install python-kaleido=0.1.0, since a later\n",
    "# version of Kaleido didn't work correctly for me. It wasn't necessary\n",
    "# to specify the version of kaleido on Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I found that Backspace and Ctrl + Backspace mapped to different bytestrings\n",
    "# on Windows and on Linux. Therefore, the following code checks the user's\n",
    "# operating system, then uses that information to choose which\n",
    "# bytestrings to assign to character_backspace and word_backspace.\n",
    "# When character_backspace is detected within V2 of the typing test, \n",
    "# a single character will be removed; meanwhile, when word_backspace \n",
    "# is detected, a whole word\n",
    "# will be removed.\n",
    "# I also found that both Delete and Command + Delete produced the same\n",
    "# bytestring on Macs, so I instead added in Fn + Delete (which maps\n",
    "# to the bytestring b'\\x7e') as a Ctrl + Backspace equivalent. However, this\n",
    "# combination will only delete the word if there's no space in between\n",
    "# the cursor and the word. Therefore, to delete words,\n",
    "# Mac players will have to first press Delete to get to the word, then\n",
    "# Fn + Delete to delete the word.\n",
    "\n",
    "import platform\n",
    "if platform.system() == 'Linux':\n",
    "    character_backspace = b'\\x7f'\n",
    "    word_backspace = b'\\x08'\n",
    "if platform.system() == 'Darwin':\n",
    "    character_backspace = b'\\x7f'\n",
    "    word_backspace = b'\\x7e'\n",
    "else:\n",
    "    character_backspace = b'\\x08'\n",
    "    word_backspace = b'\\x7f'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blessed import Terminal # Blessed is a variant of the Blessings library \n",
    "# that also works on Windows. This library contains a very useful function\n",
    "# for retrieving the current coordinates of the text cursor; this information\n",
    "# will prove very useful during gameplay.\n",
    "#  See https://blessed.readthedocs.io/en/latest/intro.html\n",
    "term = Terminal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_analyses = False # If set to True, additional analyses will be created, \n",
    "# but only when the program is run as a Jupyter notebook.\n",
    "save_image_copies_of_charts = False # I had trouble getting Kaleido \n",
    "# (the package that Plotly uses by default to generate screenshots of\n",
    "# charts) to run on pyinstaller-generated copies of Type Through The Bible,\n",
    "# so I chose to disable image generation by default. (The HTML versions\n",
    "# of these charts are more useful anyway, and disabling the screenshot\n",
    "# generation also helps the program finish its analyses more quickly.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether the program is currently running on a Jupyter notebook:\n",
    "\n",
    "(The program normally uses getch() to begin typing tests; however, I wasn't able to enter input after getch() got called within a Jupyter notebook and thus couldn't begin a typing test in that situation. Therefore, the program will use input() instead of getch() to start tests when running within a notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following method of determining whether the code is running\n",
    "# within a Jupyter notebook is based on Gustavo Bezerra's response\n",
    "# at https://stackoverflow.com/a/39662359/13097194 . I found that\n",
    "# just calling get_ipython() was sufficient, at least on Windows and within\n",
    "# Visual Studio Code.\n",
    "\n",
    "try: \n",
    "    get_ipython()\n",
    "    run_on_notebook = True\n",
    "except:\n",
    "    run_on_notebook = False\n",
    "\n",
    "# print(run_on_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Bible verses into the program:\n",
    "\n",
    "(This file derives from Bible_csv_generator.ipynb.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Bible = pd.read_csv('WEB_Catholic_Version_for_game_updated.csv', \n",
    "index_col = 'Verse_Order') # Setting Verse_Order (the position of each verse\n",
    "# within the entire Bible) as the index column will simplify the process\n",
    "# of updating this file.\n",
    "df_Bible.sort_index(inplace = True) # Helps ensure that\n",
    "# any code that relies on df_Bible's being sorted from the first to the last\n",
    "# verse will run correctly\n",
    "\n",
    "df_Bible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will now search the local directory for 'results.csv' and 'word_stats.csv', files used to store various typing statistics. If the script doesn't find these, it will go ahead and create blank DataFrames that will be replaced with actual results after the player completes a typing test.\n",
    "\n",
    "The script will also create an 'Analyses' folder for storing typing stats and visualizations if this folder does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = os.listdir()\n",
    "if 'Analyses' not in local_dir:\n",
    "    print(\"Analyses folder was not found within the directory. Adding this \\\n",
    "folder now.\")    \n",
    "    os.mkdir('Analyses')\n",
    "if 'results.csv' not in local_dir:\n",
    "    print(\"results.csv was not found within the directory. A new copy \\\n",
    "will be created.\")    \n",
    "    df_results = pd.DataFrame() # This blank DataFrame will be passed\n",
    "    # to various functions and later replaced with actual statistics.\n",
    "else:\n",
    "    df_results = pd.read_csv('results.csv', index_col='Test_Number')\n",
    "    df_results.sort_index(inplace = True)\n",
    "\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing results (e.g. due to a glitch in the code that has since been resolved)\n",
    "# df_results.drop(9466, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing unnecessary columns (e.g. due to revisions to the game's code):\n",
    "# df_results.drop([column for column in df_results if 'efficiency' in column.lower()], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to make any corrections or revisions to your setting columns (Keyboard, Location, etc.), you can do so by modifying the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results['Keyboard'].replace({'laptop':'2021 laptop', '2021':'2021 laptop'}, inplace = True)\n",
    "# df_results.to_csv('results.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you accidentally overwrote your Local_Start_Time values with something\n",
    "# # different, you can retrieve them using the following code:\n",
    "# # (Make sure to replace the time zone passed to tz_convert() with\n",
    "# # your own time zone.)\n",
    "# df_results['UTC_Start_Time'] = pd.to_datetime(\n",
    "# df_results['UTC_Start_Time']).astype('datetime64[us, UTC]')\n",
    "# df_results['Local_Start_Time'] = df_results['UTC_Start_Time'].dt.tz_convert(\n",
    "# 'America/New_York').dt.tz_localize(None)\n",
    "# # The above line was based on \n",
    "# # https://stackoverflow.com/questions/48630178/convert-the-utc-datetime-to-local-datetime-in-pandas\n",
    "# df_results.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encountered errors when trying to add new results to my pre-existing list of results; I found that these errors were caused by datetime type mismatches between df_results and the new results. The following cell resolves these issues by converting some of the datetime columns in df_results to microsecond types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_results) > 0: # If df_results is empty, then there's\n",
    "    # no need to attempt to convert its (non-existent) values.\n",
    "    df_results['Local_Start_Time'] = pd.to_datetime(\n",
    "    df_results['Local_Start_Time']).astype('datetime64[us]')\n",
    "    df_results['UTC_Start_Time'] = pd.to_datetime(\n",
    "    df_results['UTC_Start_Time']).astype('datetime64[us, UTC]')\n",
    "    df_results['WPM'] = df_results['WPM'].astype('float') # Prevents a glitch\n",
    "    # that can be caused when this column is stored as an object.\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'word_stats.csv' not in local_dir:\n",
    "    df_word_stats = pd.DataFrame() # Once again, the script will\n",
    "    # create a blank DataFrame that will later be replaced\n",
    "    # with actual data.\n",
    "    print(\"word_stats.csv was not found within the directory. A new copy \\\n",
    "will be created.\")    \n",
    "else:\n",
    "    df_word_stats = pd.read_csv('word_stats.csv')\n",
    "\n",
    "df_word_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you accidentally overwrite your Unix_Start_Time values with something else,\n",
    "# # you can recreate them using UTC_Start_Time values as follows:\n",
    "# # (This code is based on that shown in\n",
    "# # https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#from-timestamps-to-epoch )\n",
    "# df_results['Unix_Start_Time'] = ((df_results['UTC_Start_Time'] - pd.Timestamp(\n",
    "# \"1970-01-01\", tz = 'utc')) // pd.Timedelta(\"1ns\") / 1000000000)\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you ever need to drop a particular result,\n",
    "# you can do so as follows:\n",
    "# df_results.drop(17, inplace = True)\n",
    "# df_results.to_csv('results.csv') # We want to preserve the index so as not\n",
    "# to lose our 'Test_Number' values\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an RNG seed:\n",
    "\n",
    "In order to make the RNG values a bit more random, the following code will derive the RNG seed from the decimal component of the current timestamp. This seed will change 1 million times each second.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the decimal component of time.time() to select an RNG seed:\n",
    "current_time = time.time()\n",
    "decimal_component = current_time - int(current_time) # This \n",
    "# line retrieves the decimal component of current_time. int() is used instead\n",
    "# of np.round() so that the code won't ever round current_time up prior\n",
    "# to the subtraction operation, which would return a different value.\n",
    "# I don't think that converting current_time to an integer (e.g. via\n",
    "# np.int64(current_time)) is necessary, as int() appears to handle at least \n",
    "# some integers larger than 32 bits in size just fine.\n",
    "decimal_component\n",
    "random_seed = round(decimal_component * 1000000)\n",
    "decimal_component, random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(random_seed) # Based on\n",
    "# https://numpy.org/doc/stable/reference/random/index.html?highlight=random#module-numpy.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Gameplay Functions:\n",
    "\n",
    "The script will now define a series of functions that will allow the user to select verses to type; enter responses; and view gameplay statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [This fantastic answer](https://stackoverflow.com/a/23294659/13097194) by \n",
    "# Kevin at Stack Overflow proved helpful in implementing \n",
    "# entry validation code within this program. \n",
    "\n",
    "def select_verse():\n",
    "    '''This function allows the player to select an initial Bible verse \n",
    "    to type. The player can choose a random verse; a verse that hasn't\n",
    "    been typed; or a specific verse.\n",
    "    The player can also choose to enable an autostart mode, which automatically\n",
    "    commences new typing tests.\n",
    "    This function returns the verse to type followed by a boolean value\n",
    "    that specifies whether autostart is active.''' \n",
    "\n",
    "    print(\"Select a verse to type! Enter 0 to receive a random verse\\n\\\n",
    "or enter a verse number (see 'Verse_Order column of\\n\\\n",
    "the WEB_Catholic_Version.csv spreadsheet for a list of numbers to enter)\\n\\\n",
    "to select a specific verse.\\n\\\n",
    "You can also enter -2 to receive a random verse that you haven't yet typed,\\n\\\n",
    "-3 to choose the first Bible verse that hasn't yet been typed,\\n\\\n",
    "or -4 to enable autostart (which automatically begins a typing test for\\n\\\n",
    "the subsequent verse after you finish typing a verse). Autostart can be\\n\\\n",
    "canceled by hitting the ` key in version v2 of the typing test or by entering\\n\\\n",
    "'exit' as the response in version v1. \")\n",
    "    \n",
    "    verses_not_yet_typed = df_Bible.query(\n",
    "                \"Typed == 0\").copy().index.to_list()\n",
    "    while True:\n",
    "        try:\n",
    "            response = int(input())\n",
    "        except:\n",
    "            print(\"Please enter an integer corresponding to a particular Bible \\\n",
    "verse or 0 for a randomly selected verse.\")\n",
    "            continue # Allows the user to retry entering a number\n",
    "\n",
    "        if response == 0: # A random verse will be selected.\n",
    "            return (rng.integers(1, len(df_Bible) + 1), False) \n",
    "            # The number of verses within the Bible .csv file is equal to \n",
    "            # len(df_Bible), so we'll pass 1 (the first verse) and \n",
    "            # len(df_Bible) + 1 to rng.integers (as this function won't \n",
    "            # include the final number within the range.)\n",
    "        elif response == -2: # A random verse not yet typed will be selected.\n",
    "            if len(verses_not_yet_typed) == 0:\n",
    "                print(\"Congratulations! You have typed all verses from \\\n",
    "the Bible, so there are no new verses to type! Try selecting another option \\\n",
    "instead.\")\n",
    "                continue\n",
    "            print(f\"{len(verses_not_yet_typed)} verses have not yet \\\n",
    "been typed.\")\n",
    "            return (rng.choice(verses_not_yet_typed), False)\n",
    "            # Chooses one of these untyped verses at random\n",
    "        elif response == -3: # The first verse not yet typed will be selected.\n",
    "            if len(verses_not_yet_typed) == 0:\n",
    "                print(\"Congratulations! You have typed all verses from \\\n",
    "the Bible, so there are no new verses to type! Try selecting another option \\\n",
    "instead.\")\n",
    "                continue\n",
    "            print(f\"{len(verses_not_yet_typed)} verses have not yet \\\n",
    "been typed.\")\n",
    "            verses_not_yet_typed.sort() # Probably not necessary, as df_Bible\n",
    "            # was already sorted from the first to the last verse.\n",
    "            return (verses_not_yet_typed[0], False)\n",
    "        \n",
    "        elif response == -4: # This option will enable autostart.\n",
    "            if len(verses_not_yet_typed) == 0: # If all verses have already\n",
    "                # been typed, autostart mode will begin with the first verse.\n",
    "                return (1, True)\n",
    "            else: # In this case, the first verse not yet typed will\n",
    "                # be returned. (The player can commence autostart with\n",
    "                # a different verse later on in a gameplay session.)\n",
    "                return (verses_not_yet_typed[0], True)\n",
    "        \n",
    "        else: # In this case, the player either submitted a valid verse number\n",
    "            # or an invalid entry.\n",
    "            if ((response >= 1) \n",
    "            & (response <= len(df_Bible))): # Making sure that the response is \n",
    "                # an integer between 1 and the length of df_Bible so that it \n",
    "                # matches one of the Bible verse numbers present:                    \n",
    "                return (response, False) # The user entered a valid verse\n",
    "                # number, so this number will get returned by the function.\n",
    "            else: # Will be called if a non-integer number was passed\n",
    "                    # or if the integer didn't correspond to a Bible verse\n",
    "                    # number. \n",
    "                print(\"Please enter an integer that corresponds to one of the \\\n",
    "verse numbers within the Bible .csv file.\") # Since\n",
    "                # we're still within a While loop, the player will be returned\n",
    "                # to the initial try/except block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_table(verse):\n",
    "    '''This function creates a list of words within the verse that can be used\n",
    "    for word-based analyses.\n",
    "    We could use verse.split(' ') to create a list of words. However,\n",
    "    since our goal is to build a list that can then serve as the basis\n",
    "    of analyses, we'll want to create a list that includes:\n",
    "    1. The starting and finishing index of each word within the verse. This will\n",
    "    allow us to determine when the player has arrived at and completed\n",
    "    that word.\n",
    "    2. Words without any spacing or punctuation attached. (Learning how fast\n",
    "    you wrote 'they' is more interesting than is learning how fast \n",
    "    you wrote '\"that' or 'that,'.)\n",
    "    Therefore, the following code is more complex than a simple split()\n",
    "    operation.\n",
    "    This function also counts contractions ('don't', 'can't,\n",
    "    etc.) as individual words. Some care is needed to distinguish between\n",
    "    apostrophes/single quotes that begin contractions and those that start\n",
    "    or end single quotes.\n",
    "    \n",
    "    The function begins by identifying the first letter of each word in the\n",
    "    verse. It then determines the final letter of each word, then returns\n",
    "    a DataFrame with information about the words in the verse.'''\n",
    "\n",
    "    first_letter_index_list = []\n",
    "    # Determining the indices of the verse that contain starting letters of\n",
    "    # words: \n",
    "    # (We can find these indices by searching for characters that are preceded\n",
    "    # by a non-alphabetic character *or* an alphabetic character that is also\n",
    "    # the first character in the verse.\n",
    "    for i in range(1, len(verse)): # Starting at 1 rather than 0 because\n",
    "        # we'll sometimes need to reference the preceding character\n",
    "        # (which wouldn't be possible if i were 0)\n",
    "\n",
    "        if i == 1:\n",
    "            if ((verse[i].isalpha()) & (verse[i-1].isalpha() == False)): \n",
    "                # This if statement addresses a special case\n",
    "                # in which a verse begins with ' and a letter. In this \n",
    "                # case, because there are no letters preceding the ' \n",
    "                # (since i is 1), we'll assume that the ' is the start of \n",
    "                # a single quote rather than the beginning of a contraction\n",
    "                # and will thus add the letter to our starting letters list.\n",
    "                # print(\"Found first letter of word (Part A)\")\n",
    "                first_letter_index_list.append(i)\n",
    "                continue # Now that we've added i to the list, we can \n",
    "                # return to the top of the for loop. (This will prevent the\n",
    "                # code from adding duplicate copies of a starting letter\n",
    "                # to first_letter_index_list.\n",
    "\n",
    "            if (verse[i-1].isalpha()):\n",
    "                # print(\"Found first letter of word (Part B)\")\n",
    "                first_letter_index_list.append(i-1) # In this case, the\n",
    "            # character preceding i is the starting letter \n",
    "            # rather than i itself (which may or may not be a letter).\n",
    "                continue\n",
    "\n",
    "        if ((verse[i].isalpha()) & \n",
    "        ((verse[i-1].isalpha() == False) & (verse[i-1] != \"'\"))): # If \n",
    "            # the current character is a letter (e.g. isalpha() is True)\n",
    "            # and the character behind it isn't a letter *and* also isn't\n",
    "            # \"'\" (which is found in contractions), we'll assume that we\n",
    "            # have found the start of a word.\n",
    "            # This if statement will fail to detect the first word in a verse\n",
    "            # if it gets preceded by a single quote (e.g. 'Hello' in \n",
    "            # 'Hello there'), but a previous if statement\n",
    "            # will have already detected it.\n",
    "            # print(\"Found first letter of word (Part C)\")\n",
    "            first_letter_index_list.append(i)\n",
    "            continue\n",
    "    \n",
    "        if i >= 2:\n",
    "            if ((verse[i].isalpha()) & \n",
    "            ((verse[i-1].isalpha() == False)) &\n",
    "            (verse[i-2].isalpha() == False)): # In this case,\n",
    "                # if both of the characters preceding a letter\n",
    "                # aren't letters, then we'll assume that\n",
    "                # this letter begins a word. (This was added in\n",
    "                # to account for words that are preceded by a single\n",
    "                # quote. Checking the character before that single quote\n",
    "                # helps us distinguish apostrophes that begin quotes (which\n",
    "                # won't be preceded by a letter)\n",
    "                # from apostrophes that form part of contractions (which\n",
    "                # will be).\n",
    "                # print(\"Found first letter of word (Part D)\")\n",
    "                first_letter_index_list.append(i)\n",
    "                continue\n",
    "\n",
    "\n",
    "    # print(first_letter_index_list)\n",
    "\n",
    "    # Now that we've determined the index of each word's starting letter,\n",
    "    # we will go through the verse again to locate the final letter\n",
    "    # within each word.\n",
    "    df_word_index_list = []\n",
    "\n",
    "    for index in first_letter_index_list: # This code iterates through\n",
    "        # each word's starting character.\n",
    "        first_letter = verse[index]\n",
    "        # Initializing the word started by this character with \n",
    "        # the starting character:\n",
    "        word = first_letter\n",
    "        i = 0\n",
    "        while True:\n",
    "            i += 1\n",
    "            position_within_verse = index + i\n",
    "            # print(\"i is now\", i)\n",
    "            if position_within_verse < (len(verse) -1): # If this is False,\n",
    "                # then there are at least two characters left in the verse.\n",
    "                # We need to perform this check so that an upcoming if\n",
    "                # statement that reads two characters ahead won't go\n",
    "                # out of bounds.\n",
    "                next_character = verse[position_within_verse]\n",
    "                # print(f\"Next character: '{next_character}'\")\n",
    "                if (next_character.isalpha() == True) | (\n",
    "                    (next_character == \"'\") & \n",
    "                    (verse[position_within_verse + 1].isalpha() == True)): \n",
    "                    # Here, the next character will be added to the word if\n",
    "                    # (1) it's a letter or (2) it's an apostrophe followed\n",
    "                    # by a letter (which indicates that the apostrophe\n",
    "                    # is part of a contraction).\n",
    "                    word += next_character\n",
    "                else:\n",
    "                    last_letter_index = position_within_verse -1\n",
    "                    break # Now that we've found the last letter, we can\n",
    "                    # exit out of the while loop and begin to evaluate\n",
    "                    # the next first index in first_letter_index_list.\n",
    "\n",
    "            elif position_within_verse < len(verse): # In this case, \n",
    "                # we haven't yet made it to the very end of the verse.\n",
    "                # We need to use elif here rather than 'if' so that\n",
    "                # the preceding block of if statements and this one\n",
    "                # will not both return True.\n",
    "                next_character = verse[position_within_verse]\n",
    "                if next_character.isalpha() == True: # \n",
    "                    word += next_character\n",
    "                else:\n",
    "                    last_letter_index = position_within_verse -1\n",
    "                    break\n",
    "            else: # In this case, we're already at the end of the verse,\n",
    "                # so we can instead store the previous index position\n",
    "                # within last_letter_index.\n",
    "                last_letter_index = position_within_verse -1\n",
    "                break\n",
    "\n",
    "        df_word_index_list.append({'first_letter_index':index, \n",
    "            'last_letter_index': last_letter_index,\n",
    "            'word':word})\n",
    "        # print(index, last_letter_index, word)\n",
    "\n",
    "    df_word_index_list = pd.DataFrame(df_word_index_list)\n",
    "    df_word_index_list['previous_character_index'] = np.where(\n",
    "        df_word_index_list['first_letter_index'] != 0,  \n",
    "        df_word_index_list['first_letter_index'] - 1, np.NaN)\n",
    "    df_word_index_list\n",
    "    # print(\"Words identified by create_word_table():\",df_word_index_list['word'].to_list())\n",
    "    return df_word_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_typing_test(verse_order, results_table, \n",
    "    word_stats_table, setting_dict, test_type = 'v2', autostart = False):\n",
    "    '''This function, which runs a typing test for an individual verse,\n",
    "    makes up the core of Type Through The Bible's gameplay.\n",
    "    It calculates how quickly the user types the characters\n",
    "    passed to the Bible verse represented by verse_order, then saves those \n",
    "    results to the DataFrame passed to results_table. Word-level results\n",
    "    are saved to word_stats_table.\n",
    "    \n",
    "    If autostart is set to True, the function will automatically begin\n",
    "    the typing test, which saves the player a little bit of time (but\n",
    "    makes for a more intense gameplay experience).\n",
    "\n",
    "    setting_dict is a dictionary that stores player-submitted information\n",
    "    about the player's setting (location, keyboard, layout, etc).\n",
    "    its data will get added to results_table.\n",
    "    '''\n",
    "\n",
    "    # Retrieving the verse to be typed:\n",
    "    # df_Bible uses verse order values for its index, so we can access\n",
    "    # verses within df_Bible by passing verse_order to .at[].\n",
    "    verse = df_Bible.at[verse_order, 'Verse']\n",
    "    book = df_Bible.at[verse_order, 'Book_Name']\n",
    "    chapter = df_Bible.at[verse_order, 'Chapter_Name']\n",
    "    verse_number_within_chapter = df_Bible.at[verse_order, 'Verse_#']\n",
    "    \n",
    "    df_word_index_list = create_word_table(verse)\n",
    "    # print(df_word_index_list)\n",
    "\n",
    "    if run_on_notebook == False:\n",
    "        # The following two lines print ANSI escape codes that provide\n",
    "        # more space for the introduction, verse, and response.\n",
    "        print(\"\\033[2J\") # This ANSI escape code clears all text\n",
    "        # above the cursor. The print statement is based on\n",
    "        # https://en.wikipedia.org/wiki/ANSI_escape_code and\n",
    "        # https://github.com/tartley/colorama .\n",
    "        # Using 2J instead of 1J allows for previous lines to remain \n",
    "        # accessible; the user simply has to scroll up to access them.\n",
    "        # 1J would clear out all of these lines (at least on Windows).\n",
    "        print('\\033[0;0H') # This line, another ANSI escape code based on the\n",
    "        # two links shared above, moves the cursor to \n",
    "        # the top left of the screen.\n",
    "\n",
    "    # I moved these introductory comments out of the following while loop\n",
    "    # in order to simplify the dialogue presented to users during retest\n",
    "    # attempts.\n",
    "\n",
    "    print(f\"Welcome to the typing test! Your verse to type is {book} \\\n",
    "{chapter}:{verse_number_within_chapter} (verse {verse_order} \\\n",
    "within the Bible .csv file).\\n\")\n",
    "    \n",
    "    # The following if statement provides terminal resizing instructions\n",
    "    # so that players can complete longer tests within version v2. (Note that\n",
    "    # the terminal's size will get stored soon after this print statement\n",
    "    # appears; therefore, in order to update the size, the player will most\n",
    "    # likely need to restart the test.)\n",
    "    if ((len(verse) >= 1000) & (test_type == 'v2')):\n",
    "        print(\"You may need to resize your terminal in order to successfully \\\n",
    "complete this test. You can do so by starting the test; exiting out by \\\n",
    "pressing `; maximizing the terminal; and then restarting this test.\")\n",
    "\n",
    "\n",
    "    if run_on_notebook == False: # In this case, the typing test \n",
    "        # will begin after any keypress due to the use of getch().\n",
    "        print(\"Press any key to begin typing!\")\n",
    "    else:\n",
    "        print(\"Press Enter to begin the test!\")\n",
    "    \n",
    "    complete_flag = 0 # This value will only get set to 1 after the \n",
    "    # user has successfully finished a typing test.\n",
    "    while complete_flag == 0: # This while loop will continue to run\n",
    "        # until the user has completed a test.\n",
    "        print(f\"Here is the verse:\\n\\n{verse}\") \n",
    "\n",
    "        if run_on_notebook == False: # The following line crashed for me\n",
    "            # when running the program within a notebook (likely because\n",
    "            # no terminal is present in that case).\n",
    "            # V2 of the typing test uses terminal width and \n",
    "            # height information to determine how to display the player's input. \n",
    "            # These values will be determined via os.get_terminal_size() below\n",
    "            # so that the code can run correctly with different terminal \n",
    "            # configurations.\n",
    "            terminal_width, terminal_height = os.get_terminal_size()\n",
    "            # print(terminal_width, terminal_height)\n",
    "            # get_terminal_size() is cross-platform. See\n",
    "            # https://docs.python.org/3.8/library/os.html?highlight=get_terminal_size#os.get_terminal_size\n",
    "\n",
    "            # Version V2 of the test also uses the text cursor's\n",
    "            # current y position to help determine where to begin printing\n",
    "            # each line. We can retrieve this position using\n",
    "            # get_location() from Blessed, a Python library. I wasn't\n",
    "            # able to find a way to do this within colorama, \n",
    "            # but thankfully this solution works great. \n",
    "            # Visit https://blessed.readthedocs.io/en/latest/location.html \n",
    "            # for more details.\n",
    "            # The documentation page linked above warns that get_location()\n",
    "            # can take a little while to execute. I've found that it only\n",
    "            # takes 0.1 to 0.15 seconds on my (pretty fast) computer,\n",
    "            # but even this short amount could interfere with the typing\n",
    "            # experience if it gets called after each character.\n",
    "            # Therefore, we'll call get_location() before the test begins.\n",
    "            # get_location_start_time = time.perf_counter_ns()\n",
    "            cursor_y_pos, cursor_x_pos = term.get_location()\n",
    "            # print(cursor_y_pos, terminal_height)\n",
    "            if (cursor_y_pos + 1) < terminal_height: # E.g. if the line below\n",
    "            # the cursor is not the last line in the terminal or one below it\n",
    "            # I found that cursor_y_pos always seemed to be at least one row \n",
    "            # less than terminal_height even\n",
    "            # if it appeared to be at the bottom of the terminal,\n",
    "            # which is why I added +1 to that variable.\n",
    "                cursor_y_pos += 2 # This line moves the starting point\n",
    "            # of the cursor down by 3, as I found that it would sometimes\n",
    "            # overwrite the 'Start!' command that appears after\n",
    "            # the player begins the test.\n",
    "            else:\n",
    "                cursor_y_pos += 1 # In this case, the cursor only needs to be\n",
    "                # moved down one line. (Moving it down further would trigger\n",
    "                # code later on that repositions the text on the terminal,\n",
    "                # which can be distracting.)\n",
    "            # print(cursor_y_pos)\n",
    "            # get_location_end_time = time.perf_counter_ns()\n",
    "            # print(cursor_y_pos, cursor_x_pos)\n",
    "            # print((get_location_end_time - get_location_start_time)/1000000)\n",
    "            # print(\"Now printing cursor position:\")\n",
    "            # print(term.get_location())\n",
    "            # print(\"Printed cursor position.\")\n",
    "        else:\n",
    "            column_width = 120 # The default terminal column width on my\n",
    "            # copy of Windows\n",
    "\n",
    "        if run_on_notebook == False: # In this case, we can use getch()\n",
    "            # to begin the test.\n",
    "        # time.sleep(3) # I realized that players could actually begin typing\n",
    "        # during this sleep period, thus allowing them to complete the test\n",
    "        # faster than intended. Therefore, I'm now having the test start\n",
    "        # after the player hits a character of his/her choice. getch()\n",
    "        # accomplishes this task well.\n",
    "        # A simpler approach would be to add in an additional input block\n",
    "        # and have the player begin after he/she presses Enter, but that would\n",
    "        # cause the player's right hand to leave the default home row position,\n",
    "        # which could end up slowing him/her down. getch() allows any character\n",
    "        # to be pressed (such as the space bar) and thus avoids this issue.\n",
    "            if autostart == False: # If autostart is True, the player has\n",
    "                # chosen to automatically start the test, so the following\n",
    "                # line can be skipped (thus causing the test to begin\n",
    "                # right away).\n",
    "                start_character = getch() # See https://github.com/joeyespo/py-getch\n",
    "\n",
    "        else: # When running the program within a Jupyter notebook, I wasn't\n",
    "            # able to enter input after getch() was called, so I added\n",
    "            # input() below as an alternative start option.\n",
    "            if autostart == False:\n",
    "                input()\n",
    "     \n",
    "        print(\"Start!\")      \n",
    "        if test_type == 'v2':\n",
    "            # This version of the test checks the player's input after\n",
    "            # each character is typed. If the player's input is correct\n",
    "            # so far, the text will be highlighted green; otherwise,\n",
    "            # it will be highlighted red. (This allows the player to be \n",
    "            # notified of an error without the need for a line break\n",
    "            # in the console, which could prove distracting.)\n",
    "            # This function has been tested on Windows, Mac, and Linux systems.\n",
    "            verse_response = '' # This string will store the player's \n",
    "            # response.\n",
    "            incorrect_character_count = 0 # Will store how many incorrect\n",
    "            # keypresses have been entered, thus allowing accuracy \n",
    "            # statistics to be calculated.\n",
    "            backspace_count = 0 # Keeps track of how many backspaces the user\n",
    "            # has entered. This is a less precise measure of accuracy\n",
    "            # than incorrect_character_count, since a single backspace can\n",
    "            # potentially clear out an entire word.\n",
    "            word_stats_list = [] # Will store WPM stats at the word level.\n",
    "            # code_execution_time_list = []\n",
    "            keypress_count = 0 # This variable will keep track of the total\n",
    "            # number of keypresses typed by the user to complete the verse.\n",
    "            # I consider this to be the best indicator of accuracy (or, \n",
    "            # at least, extra_keystrokes), since it\n",
    "            # will include redundant keypresses that wouldn't appear in\n",
    "            # either incorrect_character_count or backspace_count.\n",
    "            # (As an example: say the user was trying to type 'thing'\n",
    "            # but ended up typing 'thnig', followed by Ctrl + Backspace\n",
    "            # (to clear out the whole word) and then 'thing'. The second\n",
    "            # 'th' wouldn't be included in incorrect_character_count, since\n",
    "            # those characters were correctly typed, but they would increase\n",
    "            # keypress_count beyond the length of the verse, thus indicating\n",
    "            # that the user typed the word less efficiently than he/she\n",
    "            # could have.\n",
    "\n",
    "            \n",
    "\n",
    "            # The following two lists will keep track of first- and last-letter\n",
    "            # indices that have already been reached by the player. These lists\n",
    "            # will be incorporated into if statements so that (1) timing for a\n",
    "            # word will begin only if that word's first letter index is not in \n",
    "            # first_letter_indices_reached and (2) timing for a word will end\n",
    "            # only if that word's last letter index is not in\n",
    "            # last_letter_indices_reached. This will prevent duplicate \n",
    "            # timing entries for the same word from getting added to the word\n",
    "            # stats list; in addition, it will prevent the player from\n",
    "            # 'resetting' the timing for a given word by returning to its \n",
    "            # first letter.\n",
    "            first_letter_indices_reached = []\n",
    "            last_letter_indices_reached = []\n",
    "\n",
    "            first_keypress = 1 # Designates whether or not the player is \n",
    "            # currently making his or her first keypress. This flag, which\n",
    "            # will be set to 0 after the first keypress is made,\n",
    "            # will help determine whether or not to begin timing the player's\n",
    "            # first word.\n",
    "            last_letter_index = -1 # Initializing this variable with a number\n",
    "            # that will never occur within the game ensures that this value \n",
    "            # won't get interpreted as an actual word starting point.\n",
    "\n",
    "            unix_start_time = time.time()\n",
    "            local_start_time = pd.Timestamp.now()\n",
    "            utc_start_time = pd.Timestamp.now(timezone.utc)\n",
    "            # I used to use ISO8601-compatible timestamps via the following\n",
    "            # lines, but decided to switch to a value that Pandas would \n",
    "            # immediately recognize as a datetime.\n",
    "            # local_start_time = datetime.now().isoformat()\n",
    "            # utc_start_time = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "            typing_start_time = time.perf_counter_ns()\n",
    "            # perf_counter_ns()\n",
    "            # measures time at the nanosecond level, which makes for more\n",
    "            # accurate timing stats, at least on Windows.\n",
    "            # See https://stackoverflow.com/questions/31526179/most-precise-timing-function-in-python#comment136785349_31526179\n",
    "            # and https://docs.python.org/3/library/time.html#time.perf_counter_ns\n",
    "            # for more details.\n",
    "            \n",
    "            while True: # This while loop allows the player to \n",
    "                # enter multiple characters.\n",
    "                # The following if statement determines whether to \n",
    "                # begin timing the player's first word right after\n",
    "                # the test begins. Timing will only\n",
    "                # begin if the length of the response is 0; the player\n",
    "                # is making his/her first keypress; and the letter is the \n",
    "                # first letter of a word in df_word_index.\n",
    "                if (len(verse_response) == 0) & (\n",
    "                    0 in df_word_index_list['first_letter_index'].to_list()\n",
    "                    ) & (first_keypress == 1):\n",
    "                    word_start_time = typing_start_time\n",
    "                    last_letter_index = df_word_index_list.query(\n",
    "                        'first_letter_index == 0').copy().iloc[0][\n",
    "                            'last_letter_index'] # This line retrieves\n",
    "                    # the index of the last letter of the word so that\n",
    "                    # the function can stop timing this word once\n",
    "                    # the last character has been typed successfully.\n",
    "                    word = df_word_index_list.query(\n",
    "                        'first_letter_index == 0').copy().iloc[0][\n",
    "                            'word']\n",
    "                    first_letter_indices_reached.append(0)\n",
    "                    # print(f\" Started typing {word}.\")\n",
    "                    typed_word_without_mistakes = 1 # This flag will be changed\n",
    "                    # to 0 if the player makes an incorrect keystroke in the\n",
    "                    # process of typing the word.\n",
    "                    # print(f\" {last_letter_index}\")\n",
    "                # code_execution_end_time = time.perf_counter_ns()\n",
    "                # if first_keypress == 0: \n",
    "                #     code_execution_time_list.append(\n",
    "                    # (code_execution_end_time - character_press_time) \n",
    "                    # / 1000000)\n",
    "                    # We divide by 1,000,000 to convert from nanoseconds \n",
    "                    # (the output\n",
    "                    # of perf_counter_ns() to milliseconds.\n",
    "                character = getch() # getch() allows each character to be \n",
    "                # checked, making it easier to identify mistyped words.\n",
    "                # The following lines assume that character is stored as a \n",
    "                # bytestring rather than as a string. (I initially developed \n",
    "                # this game within Windows, in which getch() returns \n",
    "                # a bytestring.) However, I found that getch() returned strings \n",
    "                # within Linux. Therefore, the following if statement was added \n",
    "                # in to convert these strings to bytestrings.\n",
    "                keypress_count += 1 # Will increment with every keypress,\n",
    "                # including backspaces. \n",
    "                if type(character) == str:\n",
    "                    character = character.encode()\n",
    "                character_press_time = time.perf_counter_ns() # This value\n",
    "                # will be helpful for calculating word-level typing durations.\n",
    "                first_keypress = 0 # This flag will remain at 0 for the rest\n",
    "                # of the test.\n",
    "\n",
    "                if character == character_backspace: \n",
    "                    # In this case, we'll want to remove the latest character\n",
    "                    # from verse_response in order to keep that value\n",
    "                    # in sync with what the player sees on the screen.\n",
    "                    backspace_count += 1\n",
    "                    verse_response = verse_response[:-1] # Trims the last\n",
    "                    # value off verse_response.\n",
    "                    typed_word_without_mistakes = 0\n",
    "                elif character == word_backspace: \n",
    "                    # The following code allows this sequence to remove the last\n",
    "                    # word typed, which is often a faster deletion method than\n",
    "                    # is pressing the backspace key repeatedly.\n",
    "                    verse_response = ' '.join(verse_response.rstrip(\n",
    "                        ).split(' ')[:-1])\n",
    "                    # The above line first removes all spaces from the right \n",
    "                    # of the last word typed so that they won't interfere \n",
    "                    # with the split() call. It then splits the response into \n",
    "                    # individual words; deselects the last word; and joins \n",
    "                    # the response back together.\n",
    "                    if len(verse_response) != 0: # As long as we're not at \n",
    "                        # the start of the console, it will be useful \n",
    "                        # to add the space after the last word back in so that \n",
    "                        # the player doesn't need to retype it.\n",
    "                        verse_response += ' '\n",
    "                    backspace_count += 1 # I was considering increasing \n",
    "                    # backspace_count here by the number of characters removed \n",
    "                    # through Ctrl + Backspace, but since the player only \n",
    "                    # has to press Backspace once in this operation, I decided \n",
    "                    # to still increment it by one. This means that \n",
    "                    # backspace_count may diverge significantly\n",
    "                    # from incorrect_character_count and thus \n",
    "                    # be a poorer measure of accuracy.\n",
    "                    typed_word_without_mistakes = 0\n",
    "                elif character == b'`':\n",
    "                    print('\\033[0m') # This ANSI escape code resets\n",
    "                    # the color of the text. \\033 begins the escape code,\n",
    "                    # and [0m specifies what action should be performed.\n",
    "                    # The Colorama documentation, available at\n",
    "                    # https://pypi.org/project/colorama/ ,\n",
    "                    # and Wikipedia's ANSI escape code page\n",
    "                    # (https://en.wikipedia.org/wiki/ANSI_escape_code)\n",
    "                    # helped me add escape codes into this game.\n",
    "                    # Colorama's STYLE.RESET_ALL variable could be used here\n",
    "                    # instead, but I decided to use actual ANSI escape codes\n",
    "                    # where possible.\n",
    "                    verse_response += character.decode('ascii') # Adding\n",
    "                    # this character to verse_response will allow the program\n",
    "                    # to use its presence within that string to exit the player\n",
    "                    # out of this test later on.\n",
    "                    break\n",
    "                else: \n",
    "                    # The following try/except block attempts to add\n",
    "                    # the latest character typed to verse_response.\n",
    "                    try:\n",
    "                        verse_response += character.decode('ascii')  \n",
    "                        # See https://stackoverflow.com/questions/17615414/how-to-convert-binary-string-to-normal-string-in-python3\n",
    "                    except: # Keys that fall out of the ascii subset, such as \n",
    "                        # arrow keys, could cause the above line to crash. \n",
    "                        # Therefore, when the above line fails to work, the \n",
    "                        # following 'continue' statement will allow the program \n",
    "                        # to ignore the key and move back to the beginning \n",
    "                        # of the loop.\n",
    "                        incorrect_character_count += 1 # It's assumed that\n",
    "                        # a character that could not be successfully decoded\n",
    "                        # reflected an incorrect keypress.\n",
    "                        continue\n",
    "\n",
    "                # Determining which color to use for the text:\n",
    "                if verse[0:len(verse_response)] == verse_response: # If this \n",
    "                    # returns True, the player's response is correct so far.\n",
    "                    text_color = '\\033[32m' # This ANSI escape code will make\n",
    "                    # all of the text that follows it green, indicating that\n",
    "                    # that the player has typed the text correctly so far.\n",
    "                    # For the use of Colorama to produce red and green text, see\n",
    "                    # https://pypi.org/project/colorama/\n",
    "                    # and https://stackoverflow.com/a/3332860/13097194 .\n",
    "                    # Colorama's Fore.GREEN could be used here instead.\n",
    "\n",
    "                    # Performing word-level analyses:\n",
    "                    verse_response_minus_one = len(verse_response) -1 # The \n",
    "                    # character index values in df_word_index_list start at 0, \n",
    "                    # so this variable will help us convert between verse \n",
    "                    # lengths and index positions.        \n",
    "                    \n",
    "                    if ((character != character_backspace) & \n",
    "                        (character != word_backspace)): # in this case,\n",
    "                        # the last character was neither a backspace nor\n",
    "                        # a Ctrl + Backspace combo.\n",
    "\n",
    "                        # Checking whether a word has begun or ended:\n",
    "                        # We're placing these checks within the correct \n",
    "                        # response and no backspace clauses so that a typo or \n",
    "                        # backspace won't count as having correctly begun or \n",
    "                        # ended a word. (I'm not sure it would actually be \n",
    "                        # possible to trigger the word start or \n",
    "                        # end checks with Ctrl + Backspace, but I'll include \n",
    "                        # it here just in case a clever player figures out how.)\n",
    "                        # Note that last_letter_indices_reached and \n",
    "                        # first_letter_indices_reached will be checked for the\n",
    "                        # presence of verse_response_minus_one. If it's already\n",
    "                        # there, then no action will be taken, as timing\n",
    "                        # for that word has already ended or started.\n",
    "\n",
    "                        # Checking whether the player has finished \n",
    "                        # typing a word:\n",
    "                        if (verse_response_minus_one == last_letter_index) & (\n",
    "                            last_letter_index not in \n",
    "                            last_letter_indices_reached): # The user has \n",
    "                            # finished correctly typing the current word for the \n",
    "                            # first time\n",
    "                            word_end_time = character_press_time\n",
    "                            # print(f\"Finished typing {word} in \\\n",
    "            # {(word_end_time - word_start_time) / 1000000} ms. typed_word_without_mistakes \\\n",
    "            # is set to {typed_word_without_mistakes}.\")\n",
    "                            # Adding word-level statistics to word_stats_list:\n",
    "                            # (Note that word_end_time - word_start_time is \n",
    "                            # divided by one million to convert it from\n",
    "                            # nanoseconds to milliseconds.\n",
    "                            word_stats_list.append({\"word\":word, \n",
    "                            \"word_duration (ms)\": (word_end_time - \n",
    "                            word_start_time) / 1000000, \n",
    "                            \"typed_word_without_mistakes\":\n",
    "                            typed_word_without_mistakes})\n",
    "                            last_letter_indices_reached.append(\n",
    "                                last_letter_index)\n",
    "                            # Other analyses can be added to our \n",
    "                            # word stats table later on, so we don't\n",
    "                            # need to compute them now.\n",
    "\n",
    "                        # Checking whether the player has reached the starting\n",
    "                            # point of a new word:\n",
    "                        if (verse_response_minus_one in df_word_index_list[\n",
    "                            'previous_character_index'].to_list()) & (\n",
    "                            verse_response_minus_one not in \n",
    "                            first_letter_indices_reached):\n",
    "                            # If this returns true, we know we're\n",
    "                            # at the starting point of a new word.\n",
    "                            # print(verse_response_minus_one, \n",
    "                            # df_word_index_list['previous_character_index'])\n",
    "                            # print(\"Start of new word detected (Point A).\")\n",
    "                            typed_word_without_mistakes = 1\n",
    "                            verse_response_minus_one = len(verse_response) -1\n",
    "                            word_start_time = character_press_time # The start \n",
    "                            # time of this new word is defined as the time \n",
    "                            # that the character preceding the word was pressed.\n",
    "                            # Updating last_letter_index with the location\n",
    "                            # of the final letter within this word:\n",
    "                            last_letter_index = df_word_index_list.query(\n",
    "                            \"previous_character_index == @verse_response_minus_one\").iloc[\n",
    "                            0]['last_letter_index']\n",
    "                            # Updating 'word' with the word that begins\n",
    "                            # after previous_character_index:\n",
    "                            word = df_word_index_list.query(\n",
    "                            \"previous_character_index == @verse_response_minus_one\").iloc[\n",
    "                            0]['word']\n",
    "                            # print(f\" Started typing {word}.\")\n",
    "                            first_letter_indices_reached.append(\n",
    "                            verse_response_minus_one)\n",
    "\n",
    "                else: # In this case, the most recent keystroke was a typo.\n",
    "                    typed_word_without_mistakes = 0 \n",
    "                    text_color = '\\033[31m' # Sets the verse's text to red to \n",
    "                    # designate that an error is present.\n",
    "                    if ((character != character_backspace) & \n",
    "                        (character != word_backspace)): \n",
    "                        # Backspaces won't be counted as part of the \n",
    "                        # incorrect character tally so that\n",
    "                        # players won't be double-penalized for mistyping\n",
    "                        # a character.\n",
    "                        incorrect_character_count += 1\n",
    "                \n",
    "                # Printing the player's response so far: \n",
    "                \n",
    "                # This process will involve printing the entirety of \n",
    "                # verse_response\n",
    "                # after each character is pressed rather than \n",
    "                # just the most recent character. \n",
    "                # This code is more complex than a regular print statement, \n",
    "                # but it has\n",
    "                # several advantages:\n",
    "                # 1. It allows the player to quickly determine when a typo has \n",
    "                # occurred (as the text will show up in red rather than \n",
    "                # in green).\n",
    "                # 2. It supports the use of backspace to correct responses on \n",
    "                # previous lines. (I wasn't able to navigate to a previous line \n",
    "                # using backspace when printing single characters at a time.)\n",
    "                # 3. It allows the cursor to appear to the right of the most\n",
    "                # recent character. If the latest typed line takes up the entire\n",
    "                # width of the console, the cursor will appear on the left of \n",
    "                # the following line.\n",
    "                # The development of this code involved a decent amount of \n",
    "                # trial and error. I've added in documentation in hopes\n",
    "                # of making it more intuitive. \n",
    "\n",
    "                line_count = ((len(verse_response)) // terminal_width)\n",
    "                # Uses floor division to calculate the number of full lines \n",
    "                # that the player's output takes up. This information will help \n",
    "                # the code adjust its output when the player reaches the end \n",
    "                # of the terminal.\n",
    "\n",
    "                clear_text_to_right_command = '\\033[0K' # This ANSI escape code\n",
    "                # code clears out all text\n",
    "                # to the right of the cursor, which will come in handy\n",
    "                # when the user hits Backspace or Ctrl + Backspace.\n",
    "                # Based on\n",
    "                # https://en.wikipedia.org/wiki/ANSI_escape_code\n",
    "                # and on https://pypi.org/project/colorama/\n",
    "\n",
    "                clear_text_to_left_command = '\\033[1K' # Based on\n",
    "                # https://en.wikipedia.org/wiki/ANSI_escape_code\n",
    "                # If the player returns to a previous line, this command\n",
    "                # will help ensure that the text on the lower line\n",
    "                # gets cleared out.\n",
    "\n",
    "                # In order to make the cursor appear on a new line when the \n",
    "                # player has reached the end of a line, a space will get added \n",
    "                # to the verse after it is printed (see below for more details). \n",
    "                # To compensate for this space, the ANSI escape code '\\033[D' \n",
    "                # will usually get printed, thus moving the cursor one column \n",
    "                # back. However, if the verse is one column away from the end \n",
    "                # of the line, this step won't be necessary, so an empty string \n",
    "                # can get passed to left_cursor_shift instead.\n",
    "                if terminal_width - (len(verse_response) % terminal_width) == 1:\n",
    "                    left_cursor_shift = ''\n",
    "                else:\n",
    "                    left_cursor_shift = '\\033[D'\n",
    "\n",
    "                # In order to get verses of different lengths to print \n",
    "                # correctly, it's helpful to begin each print statement \n",
    "                # from the same position. This can be accomplished by \n",
    "                # generating an ANSI escape code that moves the cursor to the \n",
    "                # same place whenever the print process begins.\n",
    "                # (Note: an earlier version of this code used an alternate \n",
    "                # solution that involved shifting the print statement up or down \n",
    "                # depending on the number of lines being printed. This solution \n",
    "                # was more complex and less intuitive than the cursor \n",
    "                # reposition option, so I replaced that code with this setup. \n",
    "                # The earlier solution *does* do a much better job of handling \n",
    "                # situations in which the response takes up the entire terminal; \n",
    "                # however, in that scenario, the player wouldn't be able to see \n",
    "                # the original verse anyway, making the game unplayable, so it's \n",
    "                # OK that the current code doesn't function well in that case.)\n",
    "                    \n",
    "                # The cursor reposition command makes use of the cursor_y_pos \n",
    "                # and cursor_x_pos values retrieved earlier via \n",
    "                # term.get_location().\n",
    "                # (I found that that function took around .1 to .15 seconds \n",
    "                # to run, so calling it after each character would slow the \n",
    "                # program down noticeably. Therefore, it's best to call it \n",
    "                # just once before the start of the typing test.)\n",
    "\n",
    "                # In most cases, the pre-existing cursor_y_pos value \n",
    "                # reflects an ideal cursor height; however, printing issues\n",
    "                # will result if the player's text extends past the final line \n",
    "                # of the terminal. Therefore, the following if statement \n",
    "                # was added in to check for and address this condition.    \n",
    "                    \n",
    "                if (cursor_y_pos + (line_count)) > terminal_height: # If this\n",
    "                    # returns True, the text response will extend past the final\n",
    "                    # line of the terminal, which would cause printing issues.\n",
    "                    print('\\n') # First, a newline will be printed in order\n",
    "                    # to shift the pre-existing text up, thus preventing it from\n",
    "                    # being overwritten.\n",
    "                    cursor_y_pos -= 2 # Next, cursor_y_position will be\n",
    "                    # decreased by 2 so that it has more room to print the text.\n",
    "                    # I initially thought -= 1 would work, since we're only\n",
    "                    # printing one newline above, but for some reason the\n",
    "                    # original text went up 2 lines. (Perhaps the terminal added\n",
    "                    # in another line to account for our going past \n",
    "                    # the final line.)\n",
    "                    # Thus, I changed the subtraction amount from\n",
    "                    # from 1 to 2. (Trial and error was definitely one of\n",
    "                    # the tools I used in writing this code!)\n",
    "\n",
    "                    # Note that, now that cursor_y_pos has been reduced by 2, \n",
    "                    # this if statement won't return True until we add \n",
    "                    # two more lines to our response.\n",
    "\n",
    "                    # print('\\a', end = '') # Prints an alert, which is \n",
    "                    # useful for debugging (since printing text would affect \n",
    "                    # the output).\n",
    "                    # See https://stackoverflow.com/a/6537650/13097194\n",
    "\n",
    "                # We're now ready to create our cursor reposition command,\n",
    "                # which is yet another ANSI escape code.\n",
    "                cursor_reposition_command = f'\\033[{cursor_y_pos};{cursor_x_pos}H'\n",
    "                # Based on https://github.com/tartley/colorama\n",
    "\n",
    "                # A print statement will now be called to display the latest \n",
    "                # version of verse_response on the screen. It will do so using \n",
    "                # the following steps:\n",
    "                # (Note: Many of the items to be printed are ANSI escape codes \n",
    "                # rather than text.)\n",
    "\n",
    "                # 1. clear_text_to_left_command gets printed so that \n",
    "                # text on a lower line will get removed if the player returns \n",
    "                # to a previous line via Backspace or Ctrl + Backspace.\n",
    "                \n",
    "                # 2. cursor_reposition_command moves the cursor to an ideal\n",
    "                # starting point for writing the text. (See notes above\n",
    "                # for more details.)\n",
    "                \n",
    "                # 3. text_color gets printed; this will make the verse red if \n",
    "                # a mistake is present and green otherwise.\n",
    "\n",
    "                # 4. The verse itself gets printed, followed by a space \n",
    "                # (in order to make a new line appear if the player has reached \n",
    "                # the end of the line). Note that no other spaces are present \n",
    "                # within the print statement.\n",
    "\n",
    "                # 5. In order to compensate for this space, left_cursor_shift \n",
    "                # is added, which usually moves the cursor back one column. \n",
    "                # (See above for more details.)\n",
    "\n",
    "                # 6. clear_text_to_right_command is printed so that text removed\n",
    "                # via Backspace or Ctrl + Backspace will no longer appear.\n",
    "\n",
    "                # This print statement sets end to '' so that the cursor will \n",
    "                # not move to a new line after the string is printed. \n",
    "                # In addition, flush is set  to True so that the player's \n",
    "                # response will appear immediately. \n",
    "                    \n",
    "                print(f\"{clear_text_to_left_command}{cursor_reposition_command}\\\n",
    "{text_color}{verse_response} {left_cursor_shift}{clear_text_to_right_command}\", \n",
    "                end = '', flush = True)\n",
    "                \n",
    "                # Version V2 of the typing test will now check to see\n",
    "                # whether the player finished typing the test correctly; \n",
    "                # if he/she has, the test will end automatically. This setup\n",
    "                # allows for a more accurate (and faster) WPM to be calculated \n",
    "                # relative to a manual option for ending the test.\n",
    "\n",
    "                if verse_response == verse: # The player has typed the test\n",
    "                    # correctly.\n",
    "                    typing_end_time = time.perf_counter_ns()\n",
    "                    typing_time = (\n",
    "                        typing_end_time - typing_start_time) / 1000000000\n",
    "                    # Since perf_counter_ns() measures time at the nanosecond \n",
    "                    # level, the output of (typing_end_time - typing_start_time) \n",
    "                    # must be divided by one billion in order to determine the \n",
    "                    # number of seconds used to type the verse.\n",
    "                    print('\\nSuccess!') # '\\n' was added before 'Success!'\n",
    "                    # so that the cursor will be moved past the lines already\n",
    "                    # printed, thus preventing words from getting overwritten.\n",
    "                    print('\\033[0m') # Resetting the text's color once again\n",
    "\n",
    "                    # Accuracy calculations:\n",
    "                    # Calculating backspaces as a percentage of verse length:\n",
    "                    backspaces_as_pct_of_length = (\n",
    "                        100 * backspace_count / len(verse)) # The 100* \n",
    "                        # multiplier converts these values from \n",
    "                        # proportions to percentages.\n",
    "\n",
    "                    # Calculating incorrect entries as a percentage of verse\n",
    "                    # length:\n",
    "                    incorrect_characters_as_pct_of_length = (\n",
    "                        100 * incorrect_character_count / len(verse))\n",
    "                    # print(\"Backspace count and incorrect character count:\",\n",
    "                    # backspace_count, incorrect_character_count)\n",
    "\n",
    "                    # Calculating the number of extra keypresses typed as a \n",
    "                    # percentage of the verse's length: (this is a helpful \n",
    "                    # measure of accuracy)\n",
    "                    extra_keystrokes_percentage = 100 * (\n",
    "                    (keypress_count - len(verse)) / len(verse))\n",
    "#                     print(f\"{keypress_count} keypresses were typed in order \\\n",
    "# to write a {len(verse)}-character verse, resulting in an \\\n",
    "# extra_keystrokes percentage of {extra_keystrokes_percentage}.\")\n",
    "                    # If no extra keystrokes were typed, we'll assume\n",
    "                    # that the player typed a mistake-free race.\n",
    "                    # (This might actually *not* be the case if\n",
    "                    # the player used a stenotype setup.)\n",
    "                    # The code previously set no_mistakes to 1\n",
    "                    # as long as no characters were typed incorrectly,\n",
    "                    # but that setup would allow races with\n",
    "                    # backspaces to be counted as mistake-free races\n",
    "                    # also.\n",
    "                    if extra_keystrokes_percentage == 0:\n",
    "                        no_mistakes = 1\n",
    "                    else:\n",
    "                        no_mistakes = 0\n",
    "\n",
    "\n",
    "                    # converting word_stats_list into a DataFrame\n",
    "                    # so that it can be added to a pre-existing\n",
    "                    # word stats table:\n",
    "                    word_stats_for_latest_test = pd.DataFrame(word_stats_list)\n",
    "                    # print(word_stats_for_latest_test)\n",
    "                    # Determining the percentage of words typed correctly:\n",
    "                    pct_of_words_typed_correctly = sum(word_stats_for_latest_test[\n",
    "                        'typed_word_without_mistakes'])/len(\n",
    "                        word_stats_for_latest_test) * 100\n",
    "                    # print(sum(word_stats_for_latest_test[\n",
    "                    # 'typed_word_without_mistakes']), \n",
    "                    # len(word_stats_for_latest_test), \n",
    "                    # pct_of_words_typed_correctly)\n",
    "                    # print(word_stats_for_latest_test)\n",
    "                    # print(f\"Code execution stats: Median: {np.median(\n",
    "                    # code_execution_time_list)}, Mean: {np.mean(\n",
    "                    # code_execution_time_list)}, Max: {max(\n",
    "                    # code_execution_time_list)}, Min: {min(\n",
    "                    # code_execution_time_list)}. All execution times: {\n",
    "                    # code_execution_time_list}\")\n",
    "                    break\n",
    "\n",
    "        elif test_type == 'v1': \n",
    "            # This is a simple typing test setup that receives input from\n",
    "            # the user when 'Enter' is pressed, then checks that input\n",
    "            # against the verse. Because it doesn't check the response\n",
    "            # for accuracy as the player types, the player might not realize\n",
    "            # a character was mistyped until the very end, which can get\n",
    "            # frustrating. Version V2 of the test addresses this issue.\n",
    "            \n",
    "            # The following variables can't be calculated using v1\n",
    "            # of the test (since the player's response is only evaluated\n",
    "            # after all words have been submitted), so they will instead\n",
    "            # be initialized as NaN values.\n",
    "            no_mistakes = np.NaN\n",
    "            backspaces_as_pct_of_length = np.NaN\n",
    "            incorrect_characters_as_pct_of_length = np.NaN\n",
    "            pct_of_words_typed_correctly = np.NaN\n",
    "            extra_keystrokes_percentage = np.NaN\n",
    "\n",
    "            # Storing various start time values:\n",
    "            unix_start_time = time.time()\n",
    "            local_start_time = pd.Timestamp.now()\n",
    "            utc_start_time = pd.Timestamp.now(timezone.utc)\n",
    "\n",
    "            typing_start_time = time.perf_counter_ns() \n",
    "\n",
    "            verse_response = input()\n",
    "            # The following code will execute once the player finishes typing \n",
    "            # and hits Enter. (Having the program evaluate the player's entry \n",
    "            # only after 'Enter' is pressed isn't the best option, as the time \n",
    "            # required to hit Enter will reduce the player's reported WPM. \n",
    "            # Version V2 stops the test right when the final correct\n",
    "            # character is typed, which will make the final WPM slightly faster.\n",
    "            typing_end_time = time.perf_counter_ns()\n",
    "            typing_time = (typing_end_time - typing_start_time) / 1000000000\n",
    "\n",
    "        if verse_response == verse: \n",
    "            print(f\"Well done! You typed the verse correctly.\")\n",
    "            complete_flag = 1 # Setting this flag to 1 allows the player to exit\n",
    "            # out of the while statement.\n",
    "        elif (verse_response.lower() == 'exit') or ('`' in verse_response):\n",
    "            print(\"Exiting typing test.\")\n",
    "            autostart = False # Entering this character will also\n",
    "            # cancel autostart, thus allowing the player to resume\n",
    "            # starting tests manually (or exit the game).\n",
    "            return results_table, word_stats_table, autostart \n",
    "            # Exits the function without saving the \n",
    "            # current test to results_table or df_Bible. This function has\n",
    "            # been updated to work with both versions of the typing\n",
    "            # test.\n",
    "        else: # This will only return True within V1.\n",
    "            print(\"Sorry, that wasn't the correct input.\")   \n",
    "            # Identifying incorrectly typed words:\n",
    "            verse_words = verse.split(' ')\n",
    "            verse_response_words = verse_response.split(' ')[0:len(verse_words)]\n",
    "            # I added in the [0:len(verse_words)] filter so that the following\n",
    "            # for loop would not attempt to access more words that were \n",
    "            # present in the original verse (which would cause the game\n",
    "            # to crash with an IndexError).\n",
    "            for i in range(len(verse_response_words)):\n",
    "                if verse_response_words[i] != verse_words[i]:\n",
    "                    print(f\"Word number {i} ('{verse_words[i]}') \\\n",
    "was typed '{verse_response_words[i]}'.\")\n",
    "                    # If the response has more or fewer words than the original\n",
    "                    # verse, some correctly typed words might appear within\n",
    "                    # this list also.\n",
    "            print(\"Try again!\") # complete_flag will still be 0 in this case,\n",
    "            # so the while loop will continue back to the beginning.\n",
    "\n",
    "    if test_type == 'v2': # Word statistics are only\n",
    "        # logged in version V2 of the test.\n",
    "        if len(word_stats_table) == 0: # If there are no\n",
    "            # pre-existing entries in word_stats_table,\n",
    "            # we can simply overwrite it with\n",
    "            # word_stats_for_latest_test.\n",
    "            word_stats_table = word_stats_for_latest_test.copy()\n",
    "        else:\n",
    "            word_stats_table = pd.concat(\n",
    "        [word_stats_table, word_stats_for_latest_test]).reset_index(\n",
    "        drop = True)\n",
    "            \n",
    "    # Calculating typing statistics:\n",
    "\n",
    "    cps = len(verse) / typing_time # Calculating characters per second\n",
    "    wpm = cps * 12 # Multiplying by 60 to convert from seconds to minutes, \n",
    "    # then dividing by 5 to convert from characters to words (a standard \n",
    "    # conversion practice).\n",
    "\n",
    "    # Creating a single-row DataFrame that stores the player's results:\n",
    "    # +1 is added to the length of the results table in order to begin\n",
    "    # test number values at 1 (rather than 0).\n",
    "\n",
    "    # \n",
    "\n",
    "    df_latest_result = pd.DataFrame(index = [\n",
    "        len(results_table)+1], data = {'Unix_Start_Time':unix_start_time, \n",
    "    'Local_Start_Time':local_start_time,\n",
    "    'UTC_Start_Time':utc_start_time,\n",
    "    'Characters':len(verse),\n",
    "    'Seconds':typing_time, \n",
    "    'CPS': cps,\n",
    "    'WPM':wpm,\n",
    "    'Mistake_Free_Test':no_mistakes,\n",
    "    'Backspaces as % of Verse Length': backspaces_as_pct_of_length,\n",
    "    'Incorrect Characters as % of Verse Length': \\\n",
    "incorrect_characters_as_pct_of_length,\n",
    "    'Book': book,\n",
    "    'Chapter': chapter,\n",
    "    'Verse #': verse_number_within_chapter,\n",
    "    'Verse':verse, \n",
    "    'Verse_Order':verse_order,\n",
    "    'Autostart': 1 if autostart == True else 0,\n",
    "    '% of Words Typed Correctly':pct_of_words_typed_correctly,\n",
    "    'Extra Keystrokes %':extra_keystrokes_percentage})\n",
    "    # Regarding the ternary operator within the autostart line: See \n",
    "    # See https://stackoverflow.com/a/394814/13097194\n",
    "    df_latest_result.index.name = 'Test_Number'\n",
    "    # Adding in variables from setting_dict to df_latest_result:\n",
    "    for variable in setting_dict:\n",
    "        df_latest_result[variable] = setting_dict[variable]\n",
    "\n",
    "\n",
    "    df_latest_result\n",
    "\n",
    "    # Adding this new row to results_table:\n",
    "\n",
    "    if len(results_table) == 0: # If there are no\n",
    "        # pre-existing entries within results_table\n",
    "        # (i.e. because this is the player's first test),\n",
    "        # we can make results_table a copy of df_latest_result.\n",
    "        # This avoids challenges related to \n",
    "        # concatenating an empty DataFrame with a non-empty one.\n",
    "        results_table = df_latest_result.copy()\n",
    "    else: # In this case, we'll use pd.concat() to\n",
    "        # add df_latest_result to the list of\n",
    "        # pre-existing results.\n",
    "        results_table = pd.concat([results_table, df_latest_result])\n",
    "    # Note: I could also have used df.at or df.iloc to add a new row\n",
    "    # to df_latest_result, but I chose a pd.concat() setup in order to ensure\n",
    "    # that the latest result would never overwrite an earlier result.\n",
    "    \n",
    "    # Rank and percentile data need to be recalculated after each test,\n",
    "    # as later results can affect the rank and percentile of earlier results.\n",
    "    # I could compute these statistics later, but calculating them here\n",
    "    # allows the player to view his/her statistics after each test.\n",
    "\n",
    "    results_table['WPM_Rank'] = results_table['WPM'].rank(\n",
    "    ascending = False, method = 'min').astype('int')\n",
    "    results_table['WPM_Percentile'] = results_table['WPM'].rank(pct=True)*100\n",
    "    latest_rank = results_table.iloc[-1]['WPM_Rank']\n",
    "    # Note: These percentile results may differ from the results\n",
    "    # calculated by np.quartile later in this function, likely a result of\n",
    "    # different calculation methodologies. These differences should narrow\n",
    "    # as more tests are completed.\n",
    "\n",
    "    latest_percentile = results_table.iloc[-1]['WPM_Percentile'].round(3)\n",
    "    number_of_tests = len(results_table)\n",
    "    last_10_avg = results_table['WPM'].rolling(10).mean().iloc[-1]\n",
    "    \n",
    "    # The player's rolling 10-race average will be NaN until he/she has\n",
    "    # completed 10 tests. Therefore, the following if statement will \n",
    "    # return a blank last 10 races report unless at least 10 tests\n",
    "    # are present in results_table.\n",
    "    if len(results_table) >= 10:\n",
    "        last_10_report = f' You have averaged \\\n",
    "{last_10_avg.round(3)} WPM over your last 10 tests.' # The space\n",
    "    # space before 'You' separates this text from the rest of\n",
    "    # the print statement below.\n",
    "    else:\n",
    "        last_10_report = ''\n",
    "\n",
    "    print(f\"Your CPS and WPM were {round(cps, 3)} and {round(wpm, 3)}, \\\n",
    "respectively. Your WPM percentile was {latest_percentile} \\\n",
    "({latest_rank} out of {number_of_tests} tests).{last_10_report}\")  \n",
    "\n",
    "    if test_type == 'v2':\n",
    "        print(f\"{round(pct_of_words_typed_correctly,2)}% of words \\\n",
    "were typed without a mistake. Your incorrect and extra keypress \\\n",
    "counts were {round(incorrect_characters_as_pct_of_length,2)}% and \\\n",
    "{round(extra_keystrokes_percentage, 2)}% of the verse's length, respectively.\")\n",
    "\n",
    "\n",
    "    # Updating df_Bible to store the player's results: (This will allow the\n",
    "    # player to track how much of the Bible he/she has typed so far)\n",
    "    df_Bible.at[verse_order, 'Typed'] = 1 # Denotes that this verse\n",
    "    # has now ben typed. Note that .loc[] would not work here because\n",
    "    # we are updating a value, not merely retrieving one.\n",
    "    df_Bible.at[verse_order, 'Tests'] += 1 # Keeps track of how \n",
    "    # many times this verse has been typed\n",
    "    fastest_wpm = df_Bible.at[verse_order, 'Fastest_WPM']\n",
    "    if ((pd.isna(fastest_wpm) == True) | (wpm > fastest_wpm)): \n",
    "        # In these cases, we should replace the pre-existing Fastest_WPM value\n",
    "        # with the WPM the player just achieved.\n",
    "        # I found that 5 > np.NaN returned False, so if I only checked for\n",
    "        # wpm > fastest_wpm, blank fastest_wpm values would never get \n",
    "        # overwritten. Therefore, I chose to also check for NaN values \n",
    "        # in the above if statement.\n",
    "        df_Bible.at[verse_order, 'Fastest_WPM'] = wpm\n",
    "\n",
    "    # Autosaving results as separate files: (That way, if the script crashes,\n",
    "    # the player won't lose all of his/her progress.)\n",
    "    if verse_order % 10 == 0: # The autosave will only take place for ~10%\n",
    "        # of the user's verses, thus saving processing time (and wear\n",
    "        # on solid state hard drives, though I'm not sure how much of \n",
    "        # a difference this would make for the SSD's longevity).\n",
    "        try:\n",
    "            results_table.to_csv('df_results_autosave.csv', index = True)\n",
    "            df_Bible.to_csv(\n",
    "            'WEB_Catholic_Version_for_game_updated_autosave.csv', index = True)\n",
    "            word_stats_table.to_csv('word_stats_autosave.csv', \n",
    "            index = False)\n",
    "            print(\"Autosave complete.\")\n",
    "        except: # If one of these files is open, the autosave might not have\n",
    "            # worked correctly.\n",
    "            print(\"At least one of the autosave files could not be saved. \\\n",
    "Close out of any open autosave files so that they can be updated later on.\")\n",
    "    return (results_table, word_stats_table, autostart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subsequent_verse(previous_verse_order, setting_dict, setting_string):\n",
    "    '''This function allows the player to specify which verse to\n",
    "    type next, or, alternatively, to exit the game.\n",
    "    This function will either return a positive number (representing a verse)\n",
    "    or a negative number (representing another command). Command codes\n",
    "    were made negative so that they wouldn't be mistaken for verse numbers.\n",
    "    \n",
    "    This function is quite similar to select_verse, but also incorporates\n",
    "    the verse_order value for the most recent verse typed \n",
    "    (previous_verse_order) along with information about the player's current\n",
    "    setting. Passing this setting information to select_subsequent_verse()\n",
    "    will make it easier for the function to modify the setting.\n",
    "    '''\n",
    "\n",
    "    print(\"Press 0 to retry the verse you just typed; \\\n",
    "1 to type the next verse; 2 to type the next verse that hasn't yet been typed; \\\n",
    "-3 to select the first verse that hasn't been typed; \\\n",
    "3 to select a different verse; \\\n",
    "-1 to save your results and exit; \\\n",
    "-2 to save your results without running the analysis \\\n",
    "portion of the script; -4 to enable autostart; \\\n",
    "and -5 to change information about your setting.\") \n",
    "# The analysis portion can take a decent amount of\n",
    "# time to run, which is why an option to save without running these analyses\n",
    "# was added in. These analyses can then get updated during a later session.\n",
    "    \n",
    "    verses_not_yet_typed = df_Bible.query(\n",
    "    \"Typed == 0\").copy().index.to_list() # verses_not_yet_typed stores\n",
    "    # verse_order values.\n",
    "    while True: \n",
    "            try:\n",
    "                response = int(input())\n",
    "            except: # The user didn't enter a number.\n",
    "                print(\"Please enter a number.\")      \n",
    "                continue\n",
    "            if response == 0:\n",
    "                return previous_verse_order, setting_dict, setting_string\n",
    "            elif response == 1:\n",
    "                if previous_verse_order == len(df_Bible):\n",
    "                    print(\"You just typed the last verse in the Bible, so \\\n",
    "there's no next verse to type! Please enter an option other than 1.\\n\")\n",
    "                    continue\n",
    "                else:\n",
    "                    return previous_verse_order + 1, setting_dict, setting_string\n",
    "            elif response == 2:\n",
    "                # In this case, we'll retrieve a list of verses that haven't\n",
    "                # yet been typed; filter that list to include only verses\n",
    "                # greater than previous_verse_order; and then select\n",
    "                # the first verse within that list (i.e. the next \n",
    "                # untyped verse).\n",
    "                if len(verses_not_yet_typed) == 0:\n",
    "                    print(\"Congratulations! You have typed all verses from \\\n",
    "the Bible, so there are no new verses to type! Try selecting another option \\\n",
    "instead.\")\n",
    "                    continue\n",
    "                print(f\"{len(verses_not_yet_typed)} verses have not yet \\\n",
    "been typed.\")\n",
    "                verses_not_yet_typed.sort() \n",
    "                # Filtering verses_not_yet_typed to include only verses\n",
    "                # whose verse_order values are greater than \n",
    "                # previous_verse_order:\n",
    "                next_untyped_verses = [verse for verse in verses_not_yet_typed \n",
    "                if verse > previous_verse_order]\n",
    "                return next_untyped_verses[0], setting_dict, setting_string\n",
    "            \n",
    "            elif response == -3:\n",
    "                if len(verses_not_yet_typed) == 0:\n",
    "                    print(\"Congratulations! You have typed all verses from \\\n",
    "the Bible, so there are no new verses to type! Try selecting another option \\\n",
    "instead.\")\n",
    "                    continue\n",
    "                print(f\"{len(verses_not_yet_typed)} verses have not yet \\\n",
    "been typed.\")\n",
    "                verses_not_yet_typed.sort()\n",
    "                return verses_not_yet_typed[0], setting_dict, setting_string\n",
    "\n",
    "            elif response == 3: # select_verse() returns two items, but\n",
    "                # select_subsequent_verse() only returns one, so we'll\n",
    "                # need to determine which single item to return\n",
    "                # based on the output of select_verse().\n",
    "                verse_order, autostart = select_verse()\n",
    "                if autostart == True: # In this case, we'll return\n",
    "                    # the autostart enable code (-4).\n",
    "                    return -4, setting_dict, setting_string\n",
    "                else: # If autostart is False, we'll just return\n",
    "                    # the verse order chosen by select_verse().\n",
    "                    return verse_order, setting_dict, setting_string\n",
    "            elif response == -5: # This response will allow the player\n",
    "                # to modify his/her setting, e.g. due to a keyboard\n",
    "                # or location change.\n",
    "                setting_dict, setting_string = retrieve_setting(setting_string)\n",
    "                # Now that the setting dictionary will be updated, the player\n",
    "                # will be presented once again with various options for\n",
    "                # his/her subsequent verse.\n",
    "                print(\"Now enter the number corresponding to your choice for \\\n",
    "your subsequent verse.\")\n",
    "                continue              \n",
    "            elif response in [-1, -2, -4]:\n",
    "                return response, setting_dict, setting_string\n",
    "            else: # A number other than one of the above options was passed.\n",
    "                print(\"Please enter a whole number from -3 to 3 (inclusive).\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_current_day_results(df):\n",
    "    ''' This function reports the number of characters, total verses, and \n",
    "    unique verses that the player has typed so far today.'''\n",
    "    if len(df) == 0:\n",
    "        result_string = \"You haven't typed any Bible verses yet today.\"\n",
    "    else:\n",
    "        df_current_day_results = df[pd.to_datetime(\n",
    "        df['Local_Start_Time']).dt.date == datetime.today().date()].copy()\n",
    "        if len(df_current_day_results) == 0: # In this case, the DataFrame\n",
    "        # isn't empty, but there still aren't any records available for\n",
    "        # today.\n",
    "            result_string = \"You haven't typed any Bible verses yet today.\"\n",
    "        else:\n",
    "            characters_typed_today = df_current_day_results['Characters'].sum()\n",
    "            total_verses_typed_today = len(df_current_day_results)\n",
    "\n",
    "            # Allowing for both singular and plural versions of 'verse' to \n",
    "            # be displayed:\n",
    "            if total_verses_typed_today == 1:\n",
    "                total_verses_string = 'verse'\n",
    "            else:\n",
    "                total_verses_string = 'verses'\n",
    "\n",
    "            unique_verses_typed_today = len(df_current_day_results[\n",
    "                'Verse_Order'].unique())\n",
    "\n",
    "            if unique_verses_typed_today == 1:\n",
    "                unique_verses_string = 'verse'\n",
    "            else:\n",
    "                unique_verses_string = 'verses'\n",
    "\n",
    "            # Rounding the average and median WPM values\n",
    "            # makes the output more readable.\n",
    "            average_wpm_today = round(df_current_day_results['WPM'].mean(), 3)\n",
    "            median_wpm_today = round(df_current_day_results['WPM'].median(), 3)\n",
    "            result_string = f\"So far today, you have typed \\\n",
    "{characters_typed_today} characters from {total_verses_typed_today} Bible \\\n",
    "{total_verses_string} (including {unique_verses_typed_today} unique \\\n",
    "{unique_verses_string}). Your mean and median WPM today are \\\n",
    "{average_wpm_today} and {median_wpm_today}, respectively.\"\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_setting(setting_string = ''):\n",
    "    '''This function allows players to provide information about their\n",
    "    setting (location, keyboard, layout, etc). This information will\n",
    "    then get stored in the results table so that they can compare results\n",
    "    for different settings (e.g. their average WPM with red keyboard switches \n",
    "    versus their average WPM with blue switches). Including this info is optional\n",
    "    but can allow for some interesting analyses.\n",
    "\n",
    "    setting_string: The most recent setting string entered by the player.'''\n",
    "\n",
    "\n",
    "    print(\"You can now enter information about your setting; this will allow \\\n",
    "you to analyze average results for different settings. This is entirely \\\n",
    "optional; you can enter information for all components, \\\n",
    "multiple components, or none.\\n\\\n",
    "Enter components within a single line. Each component should take the form \\\n",
    "of a variable code followed by a hyphen and your text entry for that variable. \\\n",
    "Separate variables by commas.\\n\\\n",
    "You can enter \\\n",
    "information for the following variables:\\n\\\n",
    "1. Your preferred typing test version (variable code: v). If you encounter \\\n",
    "difficulties with the default version, enter 'v1' (without the single quotes); \\\n",
    "otherwise, it's strongly \\\n",
    "recommended that you don't enter anything for this component, in which case \\\n",
    "the default typing test version (v2) will be used.\\n\\\n",
    "2. Your location (variable code: s). Can be 'home', 'subway', 'plane', etc.\\n\\\n",
    "3. Your keyboard (variable code: k). Consider entering either the keyboard \\\n",
    "itself or the type of key switches you are using.\\n\\\n",
    "4. Your keyboard layout (variable code: l). Can be 'qwerty', 'dvorak', etc.)\\n\\\n",
    "5. Whether you've had caffeine today (variable code: c). You can enter \\\n",
    "either 'yes' or 'no', \\\n",
    "but you can enter other strings for this section as well.\\n\\\n",
    "6, 7, and 8. You can also enter up to 3 custom variables; their variable codes \\\n",
    "are cu1, cu2, and cu3. You'll need to keep \\\n",
    "track of these variables on your own, but you can use your previous entries \\\n",
    "within the results.csv file as a reference.\\n\\\n",
    "Make sure not to use either commas or hyphens within your values.\\n\\\n",
    "Here's an example of an entry:\\n\\\n",
    "'s-home,k-cherry red,l-dvorak,c-yes' (again, omit the single quotes.)\\n\\\n",
    "You can now enter your entry below.\\n\")\n",
    "    if setting_string != '':\n",
    "        print(\"Your current setting is:\", setting_string) # Providing \n",
    "        # this information will make it easier for the player to update\n",
    "        # his/her settings if needed.\n",
    "\n",
    "    while True: # Using a loop allows players to redo their input if needed.\n",
    "        try: # Helps prevent incorrectly formatted entries from crashing\n",
    "            # the game\n",
    "            # Initializing a dictionary that will store all of the user's\n",
    "            # settings:\n",
    "            # (All settings except for Version will start out as empty strings;\n",
    "            # That way, if the user doesn't update them, we'll still have\n",
    "            # something to feed into our typing test code.)\n",
    "            setting_dict = {'Test Version':'v2', 'Location':'','Keyboard':'', \n",
    "            'Layout':'', 'Caffeine':'',\n",
    "            'Custom_1':'', 'Custom_2':'', 'Custom_3':''}\n",
    "            \n",
    "            # The game uses Version V2 of the typing test by default.\n",
    "            # However, I haven't been able to get this version\n",
    "            # to work within a Jupyter notebook, so the following lines \n",
    "            # force notebook-based runs to use version v1 \n",
    "            # regardless of the user's input.\n",
    "            if (run_on_notebook == True):\n",
    "                setting_dict['Test Version'] = 'v1'\n",
    "                print(\"Because you're running this test within \\\n",
    "a notebook, test version v1 must be used.\") \n",
    "\n",
    "            \n",
    "            setting_string = input() \n",
    "            if len(setting_string) != 0: # If the player simply hit Enter,\n",
    "                # no setting string was provided, so the following code\n",
    "                # should be skipped.\n",
    "\n",
    "                # Converting this string into a list of responses:\n",
    "                setting_list = setting_string.split(',')            \n",
    "\n",
    "                # The function will now go through each of the player's entries\n",
    "                # and use them to update different values within setting_dict.\n",
    "                for setting_entry in setting_list:\n",
    "                    setting_components = setting_entry.strip(\n",
    "                    ).lower().split('-')\n",
    "                    # Converting the entries to lowercase and stripping out \n",
    "                    # extraneous spaces will help prevent different versions\n",
    "                    # of the same value from appearing within a user's results.\n",
    "                    # print(setting_components[0], setting_components[1])\n",
    "                    setting_variable = setting_components[0] # This portion is\n",
    "                    # the variable code (e.g. 'l' for 'layout')\n",
    "                    setting_value = setting_components[1] # This portion is \n",
    "                    # the value the user entered for that code (e.g. 'dvorak'\n",
    "                    # for 'layout').\n",
    "\n",
    "                    if (setting_variable == 'v') & (\n",
    "                    setting_value in ['1', 'v1', 1]):\n",
    "                        setting_dict['Test Version'] = 'v1'\n",
    "\n",
    "                        # Because the game expects to see only 'v1' or 'v2' \n",
    "                        # as the value for 'Test Version', the code will\n",
    "                        # determine the value via an if statement.\n",
    "                        \n",
    "                    if setting_variable == 's':\n",
    "                        setting_dict['Location'] = str(setting_value)\n",
    "                    if setting_variable == 'k':\n",
    "                        setting_dict['Keyboard'] = str(setting_value)\n",
    "                    if setting_variable == 'l':\n",
    "                        setting_dict['Layout'] = str(setting_value)\n",
    "                    if setting_variable == 'c':\n",
    "                        setting_dict['Caffeine'] = str(setting_value)\n",
    "                    if setting_variable == 'cu1':\n",
    "                        setting_dict['Custom_1'] = str(setting_value)\n",
    "                    if setting_variable == 'cu2':\n",
    "                        setting_dict['Custom_2'] = str(setting_value)\n",
    "                    if setting_variable == 'cu3':\n",
    "                        setting_dict['Custom_3'] = str(setting_value)\n",
    "                    # If the code entered by a player doesn't match any of these\n",
    "                    # entries, it will simply be ignored.\n",
    "            \n",
    "            print(\"Here are your setting entries. If you need to \\\n",
    "redo your entry, type 'r' and hit Enter; otherwise, just hit Enter.\\n\\\n",
    "(Note: All entries are converted to lowercase.)\")\n",
    "            for variable in setting_dict:\n",
    "                if len(setting_dict[variable]) == 0:\n",
    "                    input_value = '(No Entry)'\n",
    "                else:\n",
    "                    input_value = setting_dict[variable]\n",
    "                print(f\"{variable}: {input_value}\")\n",
    "            setting_response = input()\n",
    "            if setting_response != 'r':\n",
    "                return setting_dict, setting_string\n",
    "            else:\n",
    "                print(\"You may now re-enter your setting information.\")\n",
    "        except:\n",
    "            print(\"Input was not formatted correctly. Please review the \\\n",
    "instructions and sample output and try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(results_table, word_stats_table):\n",
    "    '''This function runs Type Through the Bible by \n",
    "    calling various other functions. It allows users to select\n",
    "    verses to type, then runs typing tests and stores the results in\n",
    "    the DataFrame passed to results_table.'''\n",
    "    \n",
    "    print(\"Welcome to Type Through the Bible!\")\n",
    "    # The game will now share the player's progress for the current day:\n",
    "    print(calculate_current_day_results(results_table))\n",
    "\n",
    "\n",
    "    setting_dict, setting_string = retrieve_setting()\n",
    "    \n",
    "\n",
    "    # The typing version will be retrieved from setting_dict.\n",
    "    typing_test_version = setting_dict['Test Version']\n",
    "\n",
    "    # The method for exiting a test in progress differs by typing test\n",
    "    # version, so the game will now explain how the player can exit out of \n",
    "    # his/her version of the test.\n",
    "    if typing_test_version == 'v1':\n",
    "        print(\"Version 1 selected. Note that you can exit a test in \\\n",
    "progress by typing 'exit' and then hitting Enter.\")\n",
    "    if typing_test_version == 'v2':\n",
    "        print(\"Version 2 selected. Note that you can exit a test in progress \\\n",
    "by hitting the ` (backtick) key.\")\n",
    "              \n",
    "    verse_order, autostart = select_verse()\n",
    "    \n",
    "    while True: # Allows the player to continue entering responses for\n",
    "        # different versions until he or she decides to exit.\n",
    "        # The output of a given typing test will serve as the input for\n",
    "        # the next typing test; this approach allows the player's results\n",
    "        # to get updated over time.\n",
    "        results_table, word_stats_table, autostart = run_typing_test(\n",
    "            verse_order=verse_order, \n",
    "        results_table=results_table, \n",
    "        word_stats_table=word_stats_table,\n",
    "        test_type = typing_test_version,\n",
    "        autostart=autostart, setting_dict = setting_dict)\n",
    "        # The game will next share an updated progress report:\n",
    "        print(calculate_current_day_results(results_table))\n",
    "        \n",
    "        # The script will now determine which verse to present to\n",
    "        # the player next. As long as autostart isn't set to True,\n",
    "        # he/she will have the opportunity to choose the subsequent\n",
    "        # verse.\n",
    "        if autostart == True:\n",
    "            if verse_order == len(df_Bible): # In this case, the final verse\n",
    "                # of the Bible was just typed, so the player will be given\n",
    "                # the first verse of the Bible to type instead.\n",
    "                verse_order = 1\n",
    "            else:\n",
    "                verse_order += 1 # The next verse in the Bible will\n",
    "                # automatically be selected.\n",
    "        if autostart == False: # The player will now be prompted \n",
    "            # to select a new verse (or to save and quit).\n",
    "            previous_verse_order = verse_order # Saving verse_order here \n",
    "            # allows it to get retrieved for use in the autostart mode.\n",
    "            verse_order, setting_dict, setting_string = select_subsequent_verse(\n",
    "                previous_verse_order=previous_verse_order, \n",
    "                setting_dict = setting_dict, setting_string = setting_string)\n",
    "            # The typing version will now be re-retrieved from setting_dict\n",
    "            # just in case it was updated within select_subsequent_verse().\n",
    "            typing_test_version = setting_dict['Test Version']\n",
    "            if verse_order == -1: # In this case, the game will quit and the \n",
    "                # user's new test results will be saved to results_table.\n",
    "                run_analyses = 1\n",
    "                return (results_table, word_stats_table, run_analyses)\n",
    "            if verse_order == -2: # In this case, the game will quit and the \n",
    "                # user's new test results will be saved to results_table.\n",
    "                # However, the analysis portion of the script will be skipped \n",
    "                # in order to save time.\n",
    "                run_analyses = 0\n",
    "                return (results_table, word_stats_table, run_analyses)\n",
    "            if verse_order == -4: # Autostart has been turned on\n",
    "                autostart = True\n",
    "                if previous_verse_order == len(df_Bible): \n",
    "                # In this case, the final verse\n",
    "                # of the Bible was just typed, so the player will be given\n",
    "                # the first verse of the Bible to type instead.\n",
    "                    verse_order = 1\n",
    "                else:\n",
    "                    verse_order = previous_verse_order + 1 \n",
    "                    # The next verse in the Bible will\n",
    "                    # automatically be selected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of our gameplay functions have been defined, we can call run_game() to allow the user to play Type Through The Bible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results, df_word_stats, run_analyses = run_game(results_table = df_results, \n",
    "word_stats_table = df_word_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Gameplay Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in the script, the player has chosen to exit out of the game. Therefore, the script will now save his/her results via 3 .csv files and then begin creating analyses of those results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If df_results is blank (e.g. because the player exited out of his/her first typing test during his/her first game), some of the following code will likely crash, because they are expecting results to be present within df_results. Therefore, the program will exit out early instead of continuing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_results) == 0:\n",
    "    print(\"No results have been entered, so there is nothing to save or \\\n",
    "analyze. Exiting program in 5 seconds.\")\n",
    "    time.sleep(5) # Allows the user to view the above message\n",
    "    raise SystemExit # See https://stackoverflow.com/a/19747562/13097194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several columns within df_Bible will now be updated \n",
    "# to reflect the player's progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'Characters_Typed' column will have a value of 0 for verses the player\n",
    "# has not yet typed; for typed verses, it will show the number of characters\n",
    "# within that verse.\n",
    "df_Bible['Characters_Typed'] = df_Bible['Characters'] * df_Bible['Typed'] \n",
    "\n",
    "# The Total_Characters_Typed column will increase in value for a given verse\n",
    "# each time the player types that verse; this is not the case for \n",
    "# the 'Characters_Typed' column.\n",
    "df_Bible['Total_Characters_Typed'] = df_Bible['Characters'] * df_Bible['Tests']\n",
    "df_Bible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell calculates the player's overall progress in typing the Bible, then shares that progress via a print statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_typed_sum = df_Bible['Characters_Typed'].sum()\n",
    "proportion_of_Bible_typed = characters_typed_sum / df_Bible['Characters'].sum()\n",
    "\n",
    "print(f\"You have typed {characters_typed_sum} characters so far, \\\n",
    "which represents {round(100*proportion_of_Bible_typed, 4)}% of the Bible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding additional values and statistics to df_results:\n",
    "\n",
    "(The following cell was derived from [this script](https://github.com/kburchfiel/typeracer_data_analyzer/blob/master/typeracer_data_analyzer_v2.ipynb) that I wrote.)\n",
    "\n",
    "These statistics will get recreated whenever the script is run; this approach allows for the results to be revised as needed (e.g. if certain rows are removed from the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I found that it was necessary to convert the Local_Start_Time field to\n",
    "# a datetime value at this point when running the script on my Linux system.\n",
    "# This might have been due to library differences between my Linux\n",
    "# and Windows systems, however.\n",
    "df_results['Local_Start_Time'] = pd.to_datetime(df_results['Local_Start_Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here with editing (continue adding/updating documentation in subsequent cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['Last 10 Avg'] = df_results['WPM'].rolling(10).mean()\n",
    "df_results['Last 100 Avg'] = df_results['WPM'].rolling(100).mean()\n",
    "df_results['Last 1000 Avg'] = df_results['WPM'].rolling(1000).mean()\n",
    "\n",
    "df_results['Incorrect Character % Last 10 Avg'] = df_results[\n",
    "'Incorrect Characters as % of Verse Length'].rolling(10).mean()\n",
    "df_results['Incorrect Character % Last 100 Avg'] = df_results[\n",
    "'Incorrect Characters as % of Verse Length'].rolling(100).mean()\n",
    "df_results['Incorrect Character % Last 1000 Avg'] = df_results[\n",
    "'Incorrect Characters as % of Verse Length'].rolling(1000).mean()\n",
    "\n",
    "df_results['Extra Keystrokes % Last 10 Avg'] = df_results[\n",
    "'Extra Keystrokes %'].rolling(10).mean()\n",
    "df_results['Extra Keystrokes % Last 100 Avg'] = df_results[\n",
    "'Extra Keystrokes %'].rolling(100).mean()\n",
    "df_results['Extra Keystrokes % Last 1000 Avg'] = df_results[\n",
    "'Extra Keystrokes %'].rolling(1000).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_results['Local_Start_Year'] = df_results['Local_Start_Time'].dt.year\n",
    "df_results['Local_Start_Month'] = df_results['Local_Start_Time'].dt.month\n",
    "df_results['Local_Start_Date'] = df_results['Local_Start_Time'].dt.date\n",
    "df_results['Local_Start_Hour'] = df_results['Local_Start_Time'].dt.hour\n",
    "df_results['Local_Start_Minute'] = df_results['Local_Start_Time'].dt.minute\n",
    "df_results['Local_Start_10_Minute_Block'] = df_results[\n",
    "'Local_Start_Minute'] // 10 + 1\n",
    "df_results['Local_Start_15_Minute_Block'] = df_results[\n",
    "'Local_Start_Minute'] // 15 + 1\n",
    "df_results['Local_Start_30_Minute_Block'] = df_results[\n",
    "'Local_Start_Minute'] // 30 + 1\n",
    "\n",
    "df_results['Count'] = 1 # Useful for pivot tables that analyze test counts\n",
    "# by book, month, etc.\n",
    "\n",
    "# In order to more accurately calculate the largest number of characters \n",
    "# typed within a given block of time, we'll want to know the end time\n",
    "# of each test. This can be calculated as the sum of the local start time\n",
    "# and the number of seconds each test took.\n",
    "df_results['Local_End_Time'] = df_results[\n",
    "'Local_Start_Time'] + pd.to_timedelta(df_results['Seconds'], unit = 's')\n",
    "\n",
    "df_results['Local_End_Year'] = df_results['Local_End_Time'].dt.year\n",
    "df_results['Local_End_Month'] = df_results['Local_End_Time'].dt.month\n",
    "df_results['Local_End_Date'] = df_results['Local_End_Time'].dt.date\n",
    "df_results['Local_End_Hour'] = df_results['Local_End_Time'].dt.hour\n",
    "df_results['Local_End_Minute'] = df_results['Local_End_Time'].dt.minute\n",
    "df_results['Local_End_15_Minute_Block'] = df_results[\n",
    "'Local_End_Minute'] // 15 + 1\n",
    "df_results['Local_End_10_Minute_Block'] = df_results[\n",
    "'Local_End_Minute'] // 10 + 1\n",
    "df_results['Local_End_30_Minute_Block'] = df_results[\n",
    "'Local_End_Minute'] // 30 + 1\n",
    "\n",
    "# The following line uses a list comprehension to generate a cumulative average\n",
    "# of all WPM scores up until the current race. .iloc searches from 0 to i+1 for\n",
    "# each row so that that row is included in the calculation.\n",
    "df_results['cumulative_avg'] = [round(np.mean(df_results.iloc[0:i+1]['WPM']),\n",
    "3) for i in range(len(df_results))]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding session data to df_results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.at() could be used here, but it could fail if there happen to be any\n",
    "# test number gaps within df_results. Therefore, df.iloc[] will be used\n",
    "# instead. \n",
    "\n",
    "# Determining column indices that can be passed to .iloc: (It's better to\n",
    "# calculate these on demand than to hardcode numbers, as any changes to the \n",
    "# column structure of df_results could then make those hardcoded numbers\n",
    "# incorrect.\n",
    "\n",
    "# Initailizing blank Session and Test_#_Within_Session columns that\n",
    "# can then get recognized and updated in subsequent code:\n",
    "df_results['Session'] = 0 # Using 0 instead of np.NaN initializes these\n",
    "# columns as integers (the desired type for them)\n",
    "df_results['Test_#_Within_Session'] = 0\n",
    "\n",
    "\n",
    "session_col = df_results.columns.get_loc('Session')\n",
    "test_number_within_session_col = df_results.columns.get_loc(\n",
    "'Test_#_Within_Session')\n",
    "local_start_time_col = df_results.columns.get_loc('Local_Start_Time')\n",
    "local_end_time_col = df_results.columns.get_loc('Local_End_Time')\n",
    "new_session_cutoff = 300 # The loop below will calculate the time between\n",
    "# each test's end time and the next test's start time. If this duration\n",
    "# (in seconds) is greater to or equal than new_session_cutoff,\n",
    "# a new session will be assigned to the second test.\n",
    "\n",
    "\n",
    "# Initializing the first row as the first test within session 1:\n",
    "df_results.iloc[0, session_col] = 1 \n",
    "df_results.iloc[0, test_number_within_session_col] = 1\n",
    "\n",
    "\n",
    "for i in range(1, len(df_results)): # Starting at 1 because we'll be looking\n",
    "    # back one row during each iteration of the loop.\n",
    "    previous_row_session = df_results.iloc[i-1, session_col]\n",
    "    previous_row_test_within_session = df_results.iloc[\n",
    "    i-1, test_number_within_session_col]\n",
    "    if (df_results.iloc[i, local_start_time_col] - \n",
    "        df_results.iloc[i-1, local_end_time_col]).seconds >= new_session_cutoff:\n",
    "        # In this case, a new session will be assigned to this row.\n",
    "        df_results.iloc[i, session_col] = previous_row_session + 1\n",
    "        df_results.iloc[i, test_number_within_session_col] = 1\n",
    "    else: # Otherwise, this row will be interpreted as a continuation\n",
    "        # of the previous session.\n",
    "        df_results.iloc[i, session_col] = previous_row_session\n",
    "        df_results.iloc[i, test_number_within_session_col\n",
    "        ] = previous_row_test_within_session + 1\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding additional metrics to df_word_stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_stats['Count'] = 1\n",
    "df_word_stats['characters'] = df_word_stats['word'].str.len()\n",
    "df_word_stats['CPS'] = df_word_stats['characters'] / (\n",
    "df_word_stats['word_duration (ms)'] / 1000)\n",
    "df_word_stats['WPM'] = df_word_stats['CPS'] * 12\n",
    "df_word_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving results:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attempt_save(df, filename, index):\n",
    "    '''This function attempts to save the DataFrame passed to df to the file\n",
    "    specified by filename. It allows players to retry the save operation\n",
    "    if it wasn't initially successful (e.g. because the file was open at \n",
    "    the time), thus preventing them from losing their latest progress.\n",
    "    The index parameter determines whether or not the DataFrame's index\n",
    "    will be included in the .csv export. Set to True for results.csv\n",
    "    but False for Web_Catholic_Version_for_game_updated.csv.'''\n",
    "    while True:\n",
    "        try: \n",
    "            df.to_csv(filename, index = index)\n",
    "            return\n",
    "        except:\n",
    "            print(\"File could not be saved, likely because it is currently \\\n",
    "open. Try closing the file and trying again. Press Enter to retry.\")\n",
    "            input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt_save(df_Bible, 'WEB_Catholic_Version_for_game_updated.csv', \n",
    "index = True)\n",
    "# The verse_order index will be stored within this .csv file so that it can\n",
    "# be accessed during the subsequent run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt_save(df_results, 'results.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt_save(df_word_stats, 'word_stats.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Successfully saved updated copies of the Results, Word Stats, \\\n",
    "and Bible .csv files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating analyses:\n",
    "\n",
    "The script will now create a number of speed, accuracy, endurance analyses. It will also generate several visualizations of word-level statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_analyses == 0: # In this case, the analysis portion of the script will\n",
    "    # be skipped. These analyses can be updated when the game is next played.\n",
    "    print(\"Analyses won't be updated during this session. \\\n",
    "Exiting program in 3 seconds.\")\n",
    "    time.sleep(3) # Allows the user to view the above message\n",
    "    raise SystemExit # See https://stackoverflow.com/a/19747562/13097194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the player's progress in typing the entire Bible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_start_time = time.time() # Allows us to determine how long the\n",
    "# analyses took\n",
    "print(\"Updating analyses:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Bible['Count'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a tree map within Plotly that visualizes the player's progress in typing the entire Bible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating tree map(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is based on https://plotly.com/python/treemaps/\n",
    "# It's pretty amazing that such a complex visualization can be created using\n",
    "# just one line of code. Thanks Plotly!\n",
    "fig_tree_map_books_chapters_verses = px.treemap(\n",
    "    df_Bible, path = ['Book_Name', 'Chapter_Name', 'Verse_#'], \n",
    "    values = 'Characters', color = 'Typed',\n",
    "    title='Proportions of Bible Books and Chapters That Have Been Typed')\n",
    "# fig_verses_typed\n",
    "\n",
    "fig_tree_map_books_chapters_verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_tree_map_books_chapters_verses.write_html(\n",
    "    'Analyses/tree_map_books_chapters_verses.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a .png version of this figure takes much longer than does \n",
    "# generating an .html version, so a .png copy will only be created\n",
    "# if extra_analyses is set to True.\n",
    "if (run_on_notebook == True) & (extra_analyses == True) \\\n",
    "& (save_image_copies_of_charts == True):\n",
    "    fig_tree_map_books_chapters_verses.write_image(\n",
    "    'Analyses/tree_map_chapters_verses.png', width = 1920, height = 1080, \n",
    "    engine = 'kaleido', scale = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A similar chart that doesn't use the Typed column for color coding:\n",
    "# (This chart, unlike fig_tree_map_books_chapters_verses_typed above, \n",
    "# won't change unless edits are made to the code itself, so it can be \n",
    "# commented out after being run once.)\n",
    "# fig_Bible_verses.write_html('Bible_tree_map.html')\n",
    "# fig_Bible_verses = px.treemap(df_Bible, path = ['Book_Name', \n",
    "# 'Chapter_Name', 'Verse_#'], values = 'Characters')\n",
    "# fig_Bible_verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variant of the tree map shows chapters and verses rather than books,\n",
    "# chapters, and verses.\n",
    "if (run_on_notebook == True) & (extra_analyses == True):\n",
    "    fig_tree_map_chapters_verses = px.treemap(df_Bible, path = [\n",
    "        'Book_and_Chapter', 'Verse_#'], values = 'Characters', color = 'Typed',\n",
    "        title = 'Proportions of Bible Chapters and Verses That Have Been Typed')\n",
    "    fig_tree_map_chapters_verses.write_html(\n",
    "        'Analyses/tree_map_chapters_verses.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_tree_map_chapters_verses.write_image(\n",
    "        'Analyses/tree_map_chapters_verses.png', \n",
    "        width = 7680, height = 4320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variant of the tree map shows each verse as its own box, which results in \n",
    "# a very busy graph that takes a while to load within a web browser\n",
    "# (if it even loads at all).\n",
    "\n",
    "if (run_on_notebook == True) & (extra_analyses == True):\n",
    "    fig_tree_map_verses = px.treemap(df_Bible, path = [df_Bible.index], \n",
    "    values = 'Characters', color = 'Typed',\n",
    "    title = 'Proportions of Bible Verses That Have Been Typed')\n",
    "    fig_tree_map_verses.write_html('Analyses/tree_map_verses.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_tree_map_verses.write_image('Analyses/tree_map_verses_16K.png', \n",
    "                                    width = 15360, height = 8640) \n",
    "# fig_tree_map_verses.write_image('Analyses/tree_map_verses.png', width = 30720, \n",
    "# height = 17280) # Didn't end up rendering successfully, probably \n",
    "# because the dimensions were extremely large!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a bar chart that shows the proportion of each book that has been typed so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating progress analyses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters_typed_by_book = df_Bible.pivot_table(index = ['Book_Order', \n",
    "'Book_Name'], values = ['Characters', 'Characters_Typed'], \n",
    "aggfunc = 'sum').reset_index()\n",
    "df_characters_typed_by_book.rename(\n",
    "columns={'Characters_Typed':'Characters Typed'}, inplace = True)\n",
    "# Adding 'Book_Order' as the first index value allows for the pivot tables\n",
    "# and bars to be ordered by that value.\n",
    "df_characters_typed_by_book['Proportion Typed'] = df_characters_typed_by_book[\n",
    "    'Characters Typed'] / df_characters_typed_by_book['Characters']\n",
    "df_characters_typed_by_book.to_csv(\n",
    "    'Analyses/characters_typed_by_book.csv')\n",
    "df_characters_typed_by_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_percentage_of_each_book_typed = px.bar(df_characters_typed_by_book, \n",
    "x = 'Book_Name', y = 'Proportion Typed', title = 'Books by Percentage Typed')\n",
    "fig_percentage_of_each_book_typed.update_yaxes(range = [0, 1]) # Setting\n",
    "# the maximum y value as 1 better demonstrates how much of the Bible\n",
    "# has been typed so far\n",
    "fig_percentage_of_each_book_typed.update_layout(xaxis_title = 'Book', \n",
    "yaxis_title = '% Typed', yaxis_tickformat = ',.2%')\n",
    "\n",
    "fig_percentage_of_each_book_typed.write_html(\n",
    "    'Analyses/percentage_of_each_book_typed.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_percentage_of_each_book_typed.write_image(\n",
    "        'Analyses/percentage_of_each_book_typed.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_percentage_of_each_book_typed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a chart that compares the number of characters in each book with the number that have been typed:\n",
    "\n",
    "This provides a clearer view of the player's progress in typing the Bible, as each bar's height is based on the number of characters. (In contrast, bars for fully typed small books will be just as high in fig_percentage_of_each_book_typed as those for fully typed large books.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_characters_typed_in_each_book = px.bar(df_characters_typed_by_book, \n",
    "x = 'Book_Name', y = ['Characters', 'Characters Typed'], barmode = 'overlay',\n",
    "title = 'Books by Characters Typed')\n",
    "fig_characters_typed_in_each_book.update_layout(xaxis_title='Book',\n",
    "yaxis_title = 'Characters', legend_title = 'Variable')\n",
    "\n",
    "fig_characters_typed_in_each_book.write_html(\n",
    "    'Analyses/characters_typed_by_book.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_characters_typed_in_each_book.write_image(\n",
    "        'Analyses/characters_typed_by_book.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_characters_typed_in_each_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating charts that show both book- and chapter-level data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters_typed_by_book_and_chapter = df_Bible.pivot_table(index = [\n",
    "'Book_Order', 'Book_Name',  'Chapter_Name', 'Book_and_Chapter'], values = [\n",
    "    'Characters', 'Characters_Typed'], aggfunc = 'sum').reset_index()\n",
    "df_characters_typed_by_book_and_chapter[\n",
    "'Proportion Typed'] = df_characters_typed_by_book_and_chapter[\n",
    "'Characters_Typed'] / df_characters_typed_by_book_and_chapter['Characters']\n",
    "df_characters_typed_by_book_and_chapter.to_csv(\n",
    "    'Analyses/characters_typed_by_book_and_chapter.csv')\n",
    "df_characters_typed_by_book_and_chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chart shows both books (as bars) and chapters (as sections of these bars). These sections are also color coded by the proportion of each chapter that has been typed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_characters_typed_in_each_book_and_chapter = px.bar(\n",
    "df_characters_typed_by_book_and_chapter, x = 'Book_Name', y = [\n",
    "    'Characters'], color = 'Proportion Typed', \n",
    "hover_data = ['Book_Name', 'Chapter_Name'],\n",
    "title = 'Books and Chapters by Characters Typed')\n",
    "fig_characters_typed_in_each_book_and_chapter.update_layout(\n",
    "xaxis_title = 'Book', yaxis_title = 'Characters')\n",
    "\n",
    "fig_characters_typed_in_each_book_and_chapter.write_html(\n",
    "    'Analyses/characters_typed_by_book_and_chapter.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_characters_typed_in_each_book_and_chapter.write_image(\n",
    "        'Analyses/characters_typed_by_book_and_chapter.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_characters_typed_in_each_book_and_chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating similar charts at the chapter level:\n",
    "\n",
    "These proved difficult to interpret due to the narrowness of the bars, so I'm commenting this code out for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_proportion_of_each_chapter_typed = px.bar(df_characters_typed_by_chapter, \n",
    "# x = 'Book_and_Chapter', y = 'proportion_typed')\n",
    "# fig_proportion_of_each_chapter_typed.update_yaxes(range = [0, 1]) # Setting\n",
    "# # the maximum y value as 1 better demonstrates how much of the Bible\n",
    "# # has been typed so far\n",
    "# fig_proportion_of_each_chapter_typed.write_html(\n",
    "# 'Analyses/proportion_of_each_chapter_typed.html')\n",
    "# fig_proportion_of_each_chapter_typed\n",
    "\n",
    "# fig_characters_typed_in_each_chapter = px.bar(df_characters_typed_by_chapter, \n",
    "# x = 'Book_and_Chapter', y = ['Characters', 'Characters_Typed'], \n",
    "# barmode = 'overlay')\n",
    "# fig_characters_typed_in_each_chapter.write_html(\n",
    "# 'Analyses/characters_typed_by_chapter.html')\n",
    "# fig_characters_typed_in_each_chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endurance statistics (e.g. most characters/verses typed over a given time period):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing typing activity by period.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the dates with the most characters and verses typed:\n",
    "\n",
    "Note: In order to create more accurate analyses, I will filter the results to only include values with the same start and end periods. (For instance, if a given test began at 9:59 p.m. on 2023-11-17 but ended after 10 p.m., that test would get filtered out of a 'top hours by characters typed' report, since including it would extend the time frame analyzed beyond a 60-minute window.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_dates_by_characters = df_results.pivot_table(\n",
    "index = ['Local_Start_Date', 'Local_End_Date'], values = 'Characters', \n",
    "aggfunc = 'sum').reset_index().sort_values('Characters', ascending = False)\n",
    "# By using both the start and end dates as pivot index values, we've already \n",
    "# separated results with different start and end dates from ones whose \n",
    "# start and end dates are the same. (This will prevent the tests included\n",
    "# in a given date's calculation from extending beyond just that date.)\n",
    "# We'll also filter the DataFrame to exclude any results whose start\n",
    "# and end dates differ:\n",
    "df_top_dates_by_characters = df_top_dates_by_characters.query(\n",
    "\"Local_Start_Date == Local_End_Date\").head(50).copy()\n",
    "df_top_dates_by_characters['Rank'] = df_top_dates_by_characters[\n",
    "    'Characters'].rank(ascending = False, method = 'min').astype('int')\n",
    "# Creating a column that shows both the rank and date: (This also prevents\n",
    "# Plotly from converting the x axis to a date range, which would interfere\n",
    "# with the order of the chart items)\n",
    "df_top_dates_by_characters['Rank and Date'] = '#'+df_top_dates_by_characters[\n",
    "    'Rank'].astype('str') + ': ' + df_top_dates_by_characters[\n",
    "        'Local_Start_Date'].astype('str')\n",
    "df_top_dates_by_characters.reset_index(drop=True,inplace=True)\n",
    "df_top_dates_by_characters.to_csv(\n",
    "    'Analyses/top_dates_by_characters.csv', index = False)\n",
    "df_top_dates_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_dates_by_characters = px.bar(df_top_dates_by_characters, \n",
    "x = 'Rank and Date', y = 'Characters', text = 'Characters', title = \n",
    "'Highest Daily Character Counts')\n",
    "fig_top_dates_by_characters.update_xaxes(tickangle = 90)\n",
    "\n",
    "fig_top_dates_by_characters.write_html('Analyses/top_dates_by_characters.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_dates_by_characters.write_image(\n",
    "        'Analyses/top_dates_by_characters.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_dates_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_dates_by_verses = df_results.pivot_table(\n",
    "    index = ['Local_Start_Date', 'Local_End_Date'], \n",
    "    values = 'Count', aggfunc = 'sum').reset_index(\n",
    "    ).rename(columns = {'Count':'Verses'}).sort_values(\n",
    "        'Verses', ascending = False)\n",
    "df_top_dates_by_verses = df_top_dates_by_verses.query(\n",
    "    \"Local_Start_Date == Local_End_Date\").head(50).copy()\n",
    "df_top_dates_by_verses['Rank'] = df_top_dates_by_verses['Verses'].rank(\n",
    "    ascending = False, method = 'min').astype('int')\n",
    "df_top_dates_by_verses['Rank and Date'] = '#'+df_top_dates_by_verses[\n",
    "    'Rank'].astype('str') + ': ' + df_top_dates_by_verses[\n",
    "        'Local_Start_Date'].astype('str')\n",
    "df_top_dates_by_verses.reset_index(drop=True,inplace=True)\n",
    "df_top_dates_by_verses.to_csv('Analyses/top_dates_by_verses.csv', index = False)\n",
    "df_top_dates_by_verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_dates_by_verses = px.bar(df_top_dates_by_verses, \n",
    "x = 'Rank and Date', y = 'Verses', text = 'Verses',\n",
    "title = 'Highest Daily Verse Counts')\n",
    "fig_top_dates_by_verses.update_xaxes(tickangle = 90)\n",
    "\n",
    "fig_top_dates_by_verses.write_html('Analyses/top_dates_by_verses.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_dates_by_verses.write_image(\n",
    "        'Analyses/top_dates_by_verses.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_dates_by_verses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing similar analyses by month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_months_by_characters = df_results.pivot_table(\n",
    "    index = ['Local_Start_Year', 'Local_End_Year', \n",
    "    'Local_Start_Month', 'Local_End_Month'], \n",
    "    values = 'Characters', aggfunc = 'sum').reset_index(\n",
    "    ).sort_values('Characters', ascending = False)\n",
    "df_top_months_by_characters = df_top_months_by_characters.query(\n",
    "    \"Local_Start_Year == Local_End_Year & \\\n",
    "Local_Start_Month == Local_End_Month\").head(50).copy()\n",
    "\n",
    "df_top_months_by_characters['Rank'] = df_top_months_by_characters[\n",
    "'Characters'].rank(ascending = False, method = 'min').astype('int')\n",
    "df_top_months_by_characters['Rank and Month'] = '#'+df_top_months_by_characters[\n",
    "    'Rank'].astype('str') + ': ' + df_top_months_by_characters[\n",
    "        'Local_Start_Year'].astype('str') + '-' + df_top_months_by_characters[\n",
    "            'Local_Start_Month'].astype('str')\n",
    "df_top_months_by_characters.reset_index(drop=True,inplace=True)\n",
    "df_top_months_by_characters.to_csv('Analyses/top_months_by_characters.csv', \n",
    "index = False)\n",
    "df_top_months_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_months_by_characters = px.bar(df_top_months_by_characters, \n",
    "x = 'Rank and Month', y = 'Characters', text = 'Characters',\n",
    "title = 'Highest Monthly Character Counts')\n",
    "fig_top_months_by_characters.update_xaxes(tickangle = 90)\n",
    "\n",
    "fig_top_months_by_characters.write_html(\n",
    "    'Analyses/top_months_by_characters.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_months_by_characters.write_image(\n",
    "        'Analyses/top_months_by_characters.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_months_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_months_by_verses = df_results.pivot_table(\n",
    "    index = ['Local_Start_Year', 'Local_Start_Month', \n",
    "    'Local_End_Year', 'Local_End_Month'], \n",
    "    values = 'Count', aggfunc = 'sum').reset_index(\n",
    "    ).rename(columns={'Count':'Verses'}).sort_values(\n",
    "        'Verses', ascending = False)\n",
    "df_top_months_by_verses = df_top_months_by_verses.query(\n",
    "    \"Local_Start_Year == Local_End_Year & \\\n",
    "Local_Start_Month == Local_End_Month\").head(50).copy()\n",
    "\n",
    "df_top_months_by_verses['Rank'] = df_top_months_by_verses['Verses'].rank(\n",
    "    ascending = False, method = 'min').astype('int')\n",
    "df_top_months_by_verses['Rank and Month'] = '#'+df_top_months_by_verses[\n",
    "    'Rank'].astype('str') + ': ' + df_top_months_by_verses[\n",
    "        'Local_Start_Year'].astype('str') + '-' + df_top_months_by_verses[\n",
    "            'Local_Start_Month'].astype('str')\n",
    "df_top_months_by_verses.reset_index(drop=True,inplace=True)\n",
    "df_top_months_by_verses.to_csv('Analyses/top_months_by_verses.csv', \n",
    "index = False)\n",
    "df_top_months_by_verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_months_by_verses = px.bar(df_top_months_by_verses, \n",
    "x = 'Rank and Month', y = 'Verses', text = 'Verses',\n",
    "title = 'Highest Monthly Verse Counts')\n",
    "fig_top_months_by_verses.update_xaxes(tickangle = 90)\n",
    "\n",
    "fig_top_months_by_verses.write_html('Analyses/top_months_by_verses.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_months_by_verses.write_image(\n",
    "        'Analyses/top_months_by_verses.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_months_by_verses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing similar analyses for hours and for 30-, 15-, and 10-minute blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_hours_by_characters = df_results.pivot_table(index = ['Local_Start_Date', \n",
    "'Local_End_Date', 'Local_Start_Hour', 'Local_End_Hour'], values = 'Characters', \n",
    "aggfunc = 'sum').reset_index().sort_values('Characters', ascending = False)\n",
    "df_top_hours_by_characters = df_top_hours_by_characters.query(\n",
    "\"Local_Start_Date == Local_End_Date & \\\n",
    "Local_Start_Hour == Local_End_Hour\").head(100).copy()\n",
    "df_top_hours_by_characters['Hour'] = df_top_hours_by_characters[\n",
    "'Local_Start_Date'].astype('str') + ' ' + df_top_hours_by_characters[\n",
    "'Local_Start_Hour'].astype('str') \n",
    "df_top_hours_by_characters.to_csv('Analyses/top_hours_by_characters.csv', \n",
    "index = False)\n",
    "df_top_hours_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_hours_by_characters = px.bar(df_top_hours_by_characters, \n",
    "x = 'Hour', y = 'Characters', text = 'Characters',\n",
    "title = 'Highest Hourly Character Counts')\n",
    "fig_top_hours_by_characters.update_xaxes(type = 'category')\n",
    "\n",
    "fig_top_hours_by_characters.write_html('Analyses/top_hours_by_characters.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_hours_by_characters.write_image(\n",
    "        'Analyses/top_hours_by_characters.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_hours_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_30m_by_characters = df_results.pivot_table(index = ['Local_Start_Date', \n",
    "'Local_End_Date', 'Local_Start_Hour', 'Local_End_Hour', \n",
    "'Local_Start_30_Minute_Block', 'Local_End_30_Minute_Block'], \n",
    "values = 'Characters', aggfunc = 'sum').reset_index().sort_values(\n",
    "'Characters', ascending = False)\n",
    "df_top_30m_by_characters = df_top_30m_by_characters.query(\n",
    "\"Local_Start_Date == Local_End_Date & Local_Start_Hour == Local_End_Hour \\\n",
    "& Local_Start_30_Minute_Block == Local_End_30_Minute_Block\").head(100).copy()\n",
    "df_top_30m_by_characters['30-Minute Block'] = df_top_30m_by_characters[\n",
    "'Local_Start_Date'].astype('str') + ' ' + df_top_30m_by_characters[\n",
    "'Local_Start_Hour'].astype('str') + '_' + df_top_30m_by_characters[\n",
    "'Local_Start_30_Minute_Block'].astype('str')\n",
    "df_top_30m_by_characters.to_csv('Analyses/top_30m_by_characters.csv', \n",
    "index = False)\n",
    "df_top_30m_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_30m_by_characters = px.bar(df_top_30m_by_characters, \n",
    "x = '30-Minute Block', y = 'Characters', text = 'Characters', \n",
    "title = 'Highest 30-Minute Character Counts')\n",
    "fig_top_30m_by_characters.update_xaxes(type = 'category')\n",
    "\n",
    "fig_top_30m_by_characters.write_html(\n",
    "'Analyses/top_30m_blocks_by_characters.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_30m_by_characters.write_image(\n",
    "        'Analyses/top_30m_blocks_by_characters.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_30m_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_15m_by_characters = df_results.pivot_table(index = [\n",
    "'Local_Start_Date', 'Local_End_Date', 'Local_Start_Hour', 'Local_End_Hour', \n",
    "'Local_Start_15_Minute_Block', 'Local_End_15_Minute_Block'], \n",
    "values = 'Characters', aggfunc = 'sum').reset_index().sort_values(\n",
    "'Characters', ascending = False)\n",
    "# print(len(df_top_15m_by_characters))\n",
    "df_top_15m_by_characters = df_top_15m_by_characters.query(\n",
    "\"Local_Start_Date == Local_End_Date & Local_Start_Hour == Local_End_Hour & \\\n",
    "Local_Start_15_Minute_Block == Local_End_15_Minute_Block\").head(100).copy()\n",
    "df_top_15m_by_characters['15-Minute Block'] = df_top_15m_by_characters[\n",
    "'Local_Start_Date'].astype('str') + ' ' + df_top_15m_by_characters[\n",
    "'Local_Start_Hour'].astype('str') + '_' + df_top_15m_by_characters[\n",
    "'Local_Start_15_Minute_Block'].astype('str')\n",
    "# print(len(df_top_15m_by_characters))\n",
    "df_top_15m_by_characters.to_csv('Analyses/top_15m_by_characters.csv', \n",
    "index = False)\n",
    "df_top_15m_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_15m_by_characters = px.bar(df_top_15m_by_characters, \n",
    "x = '15-Minute Block', y = 'Characters', text = 'Characters',\n",
    "title = 'Highest 15-Minute Character Counts')\n",
    "fig_top_15m_by_characters.update_xaxes(type = 'category')\n",
    "\n",
    "fig_top_15m_by_characters.write_html(\n",
    "'Analyses/top_15m_blocks_by_characters.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_15m_by_characters.write_image(\n",
    "        'Analyses/top_15m_blocks_by_characters.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_15m_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_10m_by_characters = df_results.pivot_table(index = ['Local_Start_Date', \n",
    "'Local_End_Date', 'Local_Start_Hour', 'Local_End_Hour', \n",
    "'Local_Start_10_Minute_Block', 'Local_End_10_Minute_Block'], \n",
    "values = 'Characters', aggfunc = 'sum').reset_index().sort_values(\n",
    "'Characters', ascending = False)\n",
    "# print(len(df_top_10m_by_characters))\n",
    "df_top_10m_by_characters = df_top_10m_by_characters.query(\n",
    "\"Local_Start_Date == Local_End_Date & Local_Start_Hour == Local_End_Hour \\\n",
    "& Local_Start_10_Minute_Block == Local_End_10_Minute_Block\").head(100).copy()\n",
    "df_top_10m_by_characters['10-Minute Block'] = df_top_10m_by_characters[\n",
    "'Local_Start_Date'].astype('str') + ' ' + df_top_10m_by_characters[\n",
    "'Local_Start_Hour'].astype('str') + '_' + df_top_10m_by_characters[\n",
    "'Local_Start_10_Minute_Block'].astype('str')\n",
    "# print(len(df_top_10m_by_characters))\n",
    "df_top_10m_by_characters.to_csv('Analyses/top_10m_by_characters.csv', \n",
    "index = False)\n",
    "df_top_10m_by_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_10m_by_characters = px.bar(df_top_10m_by_characters, \n",
    "x = '10-Minute Block', y = 'Characters', text = 'Characters',\n",
    "title = 'Highest 10-Minute Character Counts')\n",
    "fig_top_10m_by_characters.update_xaxes(type = 'category')\n",
    "\n",
    "fig_top_10m_by_characters.write_html(\n",
    "'Analyses/top_10m_blocks_by_characters.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_10m_by_characters.write_image(\n",
    "        'Analyses/top_10m_blocks_by_characters.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_10m_by_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing WPM and accuracy data:\n",
    "\n",
    "(Some of this section's code derives from my work in [this script](https://github.com/kburchfiel/typeracer_data_analyzer/blob/master/typeracer_data_analyzer_v2.ipynb).)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating WPM and accuracy analyses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest test WPM results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_100_wpm = df_results.sort_values('WPM', ascending = False).head(\n",
    "    100).copy()\n",
    "df_top_100_wpm['Test #'] = df_top_100_wpm.index # Creating a column that stores\n",
    "# index data will make it easier to add that data into chart tooltips. (There\n",
    "# may be a more elegant way to add index data into tooltips.)\n",
    "# of charts\n",
    "df_top_100_wpm.insert(0, 'Rank', df_top_100_wpm['WPM'].rank(\n",
    "    ascending = False, method = 'min').astype('int'))\n",
    "# method = 'min' assigns the lowest rank to any rows that happen to have\n",
    "# the same WPM. See \n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rank.html\n",
    "df_top_100_wpm.to_csv('Analyses/top_100_wpm.csv')\n",
    "df_top_100_wpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_100_wpm = px.bar(df_top_100_wpm, x = 'Rank', y = 'WPM', \n",
    "text_auto = '.6s', hover_data = ['Test #', 'Local_Start_Time', 'Book', \n",
    "'Chapter', 'Verse #', 'Verse_Order'],\n",
    "title = 'Highest WPM Results for Individual Tests')\n",
    "\n",
    "fig_top_100_wpm.write_html('Analyses/top_100_wpm.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_100_wpm.write_image('Analyses/top_100_wpm.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_top_100_wpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 'Last 10 Average' values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_results) >= 10: # If fewer than 10 tests are present in df_results,\n",
    "    # there won't be anything to graph (and the following code will raise\n",
    "    # an error), so this section should be skipped.\n",
    "    df_top_last_10_avg_results = df_results.sort_values(\n",
    "    'Last 10 Avg', ascending = False).head(20).copy()\n",
    "    \n",
    "    # If the user has completed fewer than 30 races, there will still be some\n",
    "    # NaN 'Last 10 Avg' values within this dataset, so we'll want to \n",
    "    # remove those in order to avoid an IntCastingNaN error later in this\n",
    "    # cell. The following dropna() call removes those NaN values.\n",
    "    df_top_last_10_avg_results.dropna(subset = ['Last 10 Avg'], inplace = True)\n",
    "    df_top_last_10_avg_results.insert(0, 'Rank', \n",
    "    df_top_last_10_avg_results['Last 10 Avg'].rank(ascending = False, \n",
    "    method = 'min').astype('int'))\n",
    "    df_top_last_10_avg_results['Test #'] = df_top_last_10_avg_results.index\n",
    "    df_top_last_10_avg_results.to_csv('Analyses/top_last_10_avg_results.csv', \n",
    "    index = False)\n",
    "    df_top_last_10_avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_results) >= 10:\n",
    "    fig_top_last_10_average_wpm = px.bar(df_top_last_10_avg_results, \n",
    "    x = 'Rank', y = 'Last 10 Avg', \n",
    "    text_auto = '.6s', hover_data=['Test #', 'Local_Start_Time'],\n",
    "    title = 'Highest 10-Test WPM Averages')\n",
    "    fig_top_last_10_average_wpm.update_layout(\n",
    "    yaxis_title = 'Average WPM over Last 10 Tests')\n",
    "\n",
    "    fig_top_last_10_average_wpm.write_html(\n",
    "        'Analyses/top_last_10_average_wpm.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_top_last_10_average_wpm.write_image(\n",
    "            'Analyses/top_last_10_average_wpm.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_top_last_10_average_wpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing WPM results and moving averages by test number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_df_results_by_test_number = px.line(df_results.rename(\n",
    "columns = {'cumulative_avg':'Cumulative Avg'}), x = df_results.index, \n",
    "y = ['WPM', 'Last 10 Avg', 'Last 100 Avg', 'Last 1000 Avg', 'Cumulative Avg'],\n",
    "title = 'WPM by Test Number')\n",
    "# If data are not yet available for some of these Y values \n",
    "# (e.g. 'Last 100 Avg'), they won't appear on the graph, but that missing data \n",
    "# won't produce an error.\n",
    "fig_df_results_by_test_number.update_layout(yaxis_title = 'WPM')\n",
    "\n",
    "fig_df_results_by_test_number.write_html('Analyses/results_by_test_number.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_df_results_by_test_number.write_image(\n",
    "    'Analyses/results_by_test_number.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "\n",
    "fig_df_results_by_test_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating WPM histograms for (1) all tests and (2) the last 1000 tests:\n",
    "\n",
    "(Until you've taken more than 1,000 tests, these histograms will have the same appearance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_wpm_histogram = px.histogram(x = df_results['WPM'], nbins = 50, \n",
    "text_auto = True, title = 'WPM Histogram')\n",
    "fig_wpm_histogram.update_layout(bargroupgap = 0.1, xaxis_title = 'WPM', \n",
    "yaxis_title = 'Number of Tests') \n",
    "# bargroupgap = 0.1 adds a bit of space\n",
    "# in between histogram bars. See https://stackoverflow.com/a/62925197/13097194\n",
    "\n",
    "fig_wpm_histogram.write_html('Analyses/wpm_histogram.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_wpm_histogram.write_image('Analyses/wpm_histogram.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_wpm_histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_wpm_histogram_last_1000 = px.histogram(x = df_results.tail(1000)['WPM'], \n",
    "nbins = 50, text_auto = True, title = 'WPM Histogram for Last 1000 Tests')\n",
    "fig_wpm_histogram_last_1000.update_layout(bargroupgap = 0.1, \n",
    "xaxis_title = 'WPM', \n",
    "yaxis_title = 'Number of Tests') \n",
    "fig_wpm_histogram_last_1000.write_html('Analyses/wpm_histogram_last_1000.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_wpm_histogram_last_1000.write_image(\n",
    "    'Analyses/wpm_histogram_last_1000.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_wpm_histogram_last_1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating average results by month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_month = df_results.pivot_table(\n",
    "    index = ['Local_Start_Year', 'Local_Start_Month'], values = [\n",
    "'Count', 'WPM'], aggfunc = {'Count':'sum', 'WPM':'mean'}).reset_index()\n",
    "df_results_by_month['Year/Month'] = df_results_by_month[\n",
    "    'Local_Start_Year'].astype('str') + '-' + df_results_by_month[\n",
    "    'Local_Start_Month'].astype('str')\n",
    "df_results_by_month.rename(columns = {'Count':'Number of Tests'}, \n",
    "inplace = True)\n",
    "df_results_by_month.to_csv('Analyses/results_by_month.csv', index = False)\n",
    "df_results_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_results_by_month = px.bar(df_results_by_month, x = 'Year/Month', \n",
    "y = 'WPM', color = 'Number of Tests', text_auto = '.6s', \n",
    "title = 'Average WPM by Month')\n",
    "fig_results_by_month.update_xaxes(type = 'category') # This line, based on\n",
    "# Pracheta's response at https://stackoverflow.com/a/64424308/13097194,\n",
    "# updates the axes to show the date-month pairs as strings rather than \n",
    "# as Plotly-formatted date values. This will also prevent missing\n",
    "# months from appearing in the graph.\n",
    "fig_results_by_month.update_layout(legend_title_text = 'Test Count')\n",
    "\n",
    "fig_results_by_month.write_html('Analyses/results_by_month.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_results_by_month.write_image('Analyses/results_by_month.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_results_by_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating average results by hour of day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_hour = df_results.pivot_table(index = ['Local_Start_Hour'], \n",
    "values = ['Count', 'WPM'], \n",
    "aggfunc = {'Count':'sum', 'WPM':'mean'}).reset_index()\n",
    "df_results_by_hour.rename(columns = {'Count':'Number of Tests'}, inplace = True)\n",
    "df_results_by_hour.to_csv('Analyses/results_by_hour.csv')\n",
    "df_results_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_results_by_hour = px.bar(df_results_by_hour, x = 'Local_Start_Hour', \n",
    "y = 'WPM', color = 'Number of Tests', text_auto = '.6s',\n",
    "title = 'Average WPM by Hour')\n",
    "fig_results_by_hour.update_layout(xaxis_title = 'Hour')\n",
    "fig_results_by_hour.write_html('Analyses/results_by_hour.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_results_by_hour.write_image('Analyses/results_by_hour.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_results_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean WPMs of Bible books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wpm_by_book = df_results.pivot_table(index = 'Book', values = 'WPM', \n",
    "aggfunc = ['count', 'mean'], margins = True, \n",
    "margins_name = 'Total').reset_index()\n",
    "df_wpm_by_book.columns = 'Book', 'Tests', 'WPM'\n",
    "df_wpm_by_book.sort_values('WPM', ascending = False, inplace = True)\n",
    "df_wpm_by_book.reset_index(drop=True,inplace=True)\n",
    "df_wpm_by_book.to_csv('Analyses/mean_wpm_by_book.csv')\n",
    "df_wpm_by_book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following chart will display a bar for each book for which at least one \n",
    "# test has been taken. It will also show a line that corresponds to the player's\n",
    "# overall WPM across all books. The bars are colored by test count, making\n",
    "# it easier to identify which bars might be skewed by a low number of results.\n",
    "# The 'Total' value in df_wpm_by_book is displayed as a line instead of as\n",
    "# a color so as not to interfere with the color gradient.\n",
    "\n",
    "# Retrieving the total mean WPM value in df_wpm_by_book:\n",
    "total_mean_wpm = df_wpm_by_book.query(\"Book == 'Total'\").iloc[0]['WPM']\n",
    "total_mean_wpm\n",
    "\n",
    "fig_mean_wpm_by_book = px.bar(df_wpm_by_book.query(\"Book != 'Total'\"), \n",
    "x = 'Book', y = 'WPM', color = 'Tests', text_auto = '.6s', \n",
    "title = 'Average WPM by Book')\n",
    "fig_mean_wpm_by_book.add_shape(type = 'line', x0 = -0.5, \n",
    "x1 = len(df_wpm_by_book) -1.5, y0 = total_mean_wpm, \n",
    "y1 = total_mean_wpm, label = {'textposition':'end',\n",
    "'text':f'Average overall WPM: {total_mean_wpm.round(3)}'})\n",
    "# See https://plotly.com/python/shapes/ for the add_shape() code.\n",
    "# The use of -0.5 and len() - 1.5 is based on gleasocd's answer at \n",
    "# https://stackoverflow.com/a/40408960/13097194 . len(df) - 0.5 would normally\n",
    "# work, except that I reduced the size of the DataFrame by 1 when excluding\n",
    "# the 'Total' book.\n",
    "fig_mean_wpm_by_book.write_html('Analyses/mean_wpm_by_book.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_mean_wpm_by_book.write_image('Analyses/mean_wpm_by_book.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_mean_wpm_by_book\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean WPM for error-free and non-error free tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll only create the graph if there is at least one mistake-free\n",
    "# result and one result with errors. (Otherwise, we won't be able to\n",
    "# compare these two outcomes.)\n",
    "if (len(df_results.query(\"Mistake_Free_Test == 0\")) >= 1) & (\n",
    "    len(df_results.query(\"Mistake_Free_Test == 1\")) >= 1):\n",
    "    df_wpm_by_mistake_free_status = df_results.pivot_table(\n",
    "    index = 'Mistake_Free_Test', values = ['WPM', 'Count'], \n",
    "    aggfunc = {'WPM':'mean', 'Count':'sum'}).reset_index()\n",
    "    df_wpm_by_mistake_free_status.rename(columns = {'Count':'Tests'}, \n",
    "    inplace = True)\n",
    "    df_wpm_by_mistake_free_status['Mistake_Free_Test'].replace(\n",
    "    {0:'No', 1:'Yes'}, inplace = True)\n",
    "    df_wpm_by_mistake_free_status.to_csv(\n",
    "    'Analyses/wpm_by_mistake_free_status.csv', index = False)\n",
    "    df_wpm_by_mistake_free_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll only create the graph if there is at least one mistake-free\n",
    "# result and one result with errors. (Otherwise, we won't be able\n",
    "# to compare these two outcomes.)\n",
    "if (len(df_results.query(\"Mistake_Free_Test == 0\")) >= 1) & (\n",
    "    len(df_results.query(\"Mistake_Free_Test == 1\")) >= 1):\n",
    "    fig_wpm_by_mistake_free_status = px.bar(df_wpm_by_mistake_free_status, \n",
    "    x = 'Mistake_Free_Test', y = 'WPM', text_auto = '.6s', \n",
    "    color = 'Tests', title = 'Average WPM by Mistake-Free Status')\n",
    "    fig_wpm_by_mistake_free_status.update_layout(\n",
    "    xaxis_title = 'Mistake-Free Test')\n",
    "    fig_wpm_by_mistake_free_status.write_html(\n",
    "'Analyses/mean_wpm_by_mistake_free_status.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_wpm_by_mistake_free_status.write_image(\n",
    "        'Analyses/mean_wpm_by_mistake_free_status.png', width = 1920, \n",
    "        height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_wpm_by_mistake_free_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy measures:\n",
    "\n",
    "Note: I am now using the Extra Keystrokes Percentage measure as an indicator of accuracy, as it captures more incorrect/redundant keystrokes than do the other accuracy measures logged by the gameplay code. Lower extra keystrokes percentage values indicate more efficient, accurate tests. The lowest-possible (e.g. best) percentage with a regular keyboard is 0%; this value indicates that the player typed the verse perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the relationship between incorrect keypresses as a % of verse length and WPM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the following code created a runtime error within the \n",
    "# pyinstaller-created\n",
    "# .exe version of the program, so I'm excluding the \"trendline = 'ols'\" \n",
    "# component for now. Hopefully I can find a way to get that code to work\n",
    "# in the future.\n",
    "# fig_extra_keystrokes_wpm_scatter = px.scatter(df_results, \n",
    "# x = 'Total Keypresses as % of Verse Length', y = 'WPM', trendline = 'ols')\n",
    "# # Note that you can hover over the best fit line to see the \n",
    "# regression results.\n",
    "\n",
    "fig_extra_keystrokes_wpm_scatter = px.scatter(df_results, \n",
    "x = 'Extra Keystrokes %', y = 'WPM', \n",
    "title = 'Comparison Between Extra Keystrokes and WPM')\n",
    "\n",
    "\n",
    "fig_extra_keystrokes_wpm_scatter.write_html(\n",
    "'Analyses/extra_keystrokes_wpm_scatter.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_extra_keystrokes_wpm_scatter.write_image(\n",
    "    'Analyses/extra_keystrokes_wpm_scatter.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_extra_keystrokes_wpm_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_accuracy_wpm_histogram = px.histogram(df_results, \n",
    "x = 'Extra Keystrokes %', y = 'WPM', \n",
    "histfunc = 'avg', nbins = 20, text_auto = '.6s',\n",
    "title = 'Average WPM for Different Extra Keystrokes Bins')\n",
    "fig_accuracy_wpm_histogram.update_layout(bargroupgap = 0.1, \n",
    "yaxis_title = 'Average WPM')\n",
    "fig_accuracy_wpm_histogram.write_html(\n",
    "'Analyses/extra_keystrokes_wpm_histogram.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_accuracy_wpm_histogram.write_image(\n",
    "    'Analyses/extra_keystrokes_wpm_histogram.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_accuracy_wpm_histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_extra_keystrokes_count_histogram = px.histogram(df_results, \n",
    "x = 'Extra Keystrokes %', nbins = 20, text_auto = True,\n",
    "title = 'Extra Keystrokes Histogram')\n",
    "fig_extra_keystrokes_count_histogram.update_layout(\n",
    "bargroupgap = 0.1, yaxis_title = '# of Tests')\n",
    "fig_extra_keystrokes_count_histogram.write_html(\n",
    "'Analyses/extra_keystrokes_pct_histogram.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_extra_keystrokes_count_histogram.write_image(\n",
    "    'Analyses/extra_keystrokes_pct_histogram.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_extra_keystrokes_count_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing trends in accuracy over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_extra_keystrokes_by_test_number = px.line(\n",
    "df_results, x = df_results.index, \n",
    "y = ['Extra Keystrokes %',\n",
    "'Extra Keystrokes % Last 10 Avg',\n",
    "'Extra Keystrokes % Last 100 Avg',\n",
    "'Extra Keystrokes % Last 1000 Avg'],\n",
    "title = 'Extra Keystrokes as % of Verse Length by Test Number')\n",
    "fig_extra_keystrokes_by_test_number.update_layout(yaxis_title='Percentage')\n",
    "fig_extra_keystrokes_by_test_number.write_html(\n",
    "'Analyses/extra_keystrokes_pct_over_time.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "     fig_extra_keystrokes_by_test_number.write_image(\n",
    "     'Analyses/extra_keystrokes_pct_over_time.png', \n",
    "     width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_extra_keystrokes_by_test_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average WPM by day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_wpm_by_day = df_results.pivot_table(index = 'Local_Start_Date', \n",
    "values = ['WPM', 'Characters'], aggfunc = {\n",
    "'WPM':'mean', 'Characters':'sum'}).reset_index()\n",
    "character_threshold = 5000\n",
    "# The following code limits the results to dates with at least \n",
    "# character_threshold characters typed; this \n",
    "# step will help prevent the chart from getting skewed by dates with\n",
    "# very low character counts (which may have unusually high/low average WPMs).\n",
    "df_avg_wpm_by_day.query(\"Characters >= @character_threshold\", inplace = True)\n",
    "df_avg_wpm_by_day.to_csv('Analyses/average_wpm_by_day.csv', index = False)\n",
    "df_avg_wpm_by_day.reset_index(drop=True,inplace=True)\n",
    "df_avg_wpm_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the use of <br>, <sub>, and <i> to add a smaller, italicized\n",
    "# subtitle below the chart's main title. See\n",
    "# https://plotly.com/chart-studio-help/adding-HTML-and-links-to-charts/\n",
    "# for other HTML formatting tags that Plotly supports.\n",
    "fig_avg_wpm_by_day = px.line(df_avg_wpm_by_day, x = 'Local_Start_Date', \n",
    "y = 'WPM', title = f'Average WPM by Day<br><sub><i>Note: This chart only \\\n",
    "includes dates on which at least {character_threshold} characters \\\n",
    "were typed.</i></sub>')\n",
    "fig_avg_wpm_by_day.update_xaxes(type='category')\n",
    "fig_avg_wpm_by_day.update_layout(xaxis_title = 'Start Date (Local)')\n",
    "fig_avg_wpm_by_day.write_html('Analyses/avg_wpm_by_day.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_avg_wpm_by_day.write_image('Analyses/avg_wpm_by_day.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_avg_wpm_by_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a bar chart that features the days with the highest average WPM results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_top_daily_wpm_averages = px.bar(df_avg_wpm_by_day.sort_values(\n",
    "'WPM', ascending = False).head(50).copy(), x = 'Local_Start_Date', \n",
    "y = 'WPM', text_auto = '.6s', color = 'Characters', \n",
    "title = f'Highest Daily WPM Averages\\\n",
    "<br><sub><i>Note: This chart only \\\n",
    "includes dates on which at least {character_threshold} characters \\\n",
    "were typed.</i></sub>')\n",
    "fig_top_daily_wpm_averages.update_xaxes(type='category')\n",
    "fig_top_daily_wpm_averages.update_layout(xaxis_title = 'Start Date (Local)')\n",
    "fig_top_daily_wpm_averages.write_html('Analyses/top_daily_wpm_averages.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_top_daily_wpm_averages.write_image(\n",
    "    'Analyses/top_daily_wpm_averages.png', \n",
    "    width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "\n",
    "fig_top_daily_wpm_averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating WPM percentile data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wpm_by_percentile = df_results['WPM'].quantile(\n",
    "q = np.arange(0, 1.05, 0.05)).transpose().reset_index()\n",
    "df_wpm_by_percentile.columns = ['Percentile', 'WPM']\n",
    "df_wpm_by_percentile['Percentile'] = (\n",
    "df_wpm_by_percentile['Percentile']*100).astype('int')\n",
    "# Some of the WPM values had additional decimal values (e.g. 15.000000000000002,\n",
    "# might currently have additional decimal values, so rounding them as integers\n",
    "# helps simplify them.\n",
    "df_wpm_by_percentile.to_csv('Analyses/wpm_by_percentile.csv', index = False)\n",
    "df_wpm_by_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_wpm_by_percentile = px.bar(df_wpm_by_percentile, x = 'Percentile', \n",
    "y = 'WPM', text_auto = '.6s', title = 'WPM Percentiles')\n",
    "fig_wpm_by_percentile.update_xaxes(type = 'category')\n",
    "fig_wpm_by_percentile.write_html('Analyses/wpm_by_percentile.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_wpm_by_percentile.write_image(\n",
    "    'Analyses/wpm_by_percentile.png', width = 1920, \n",
    "    height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_wpm_by_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating WPM data for within-session test numbers:\n",
    "\n",
    "These data can help players determine how long it takes for their fingers to warm up when beginning a session (e.g. a set of consecutive tests) and, conversely, when fatigue begins to set in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average WPMs for within-session test numbers:\n",
    "\n",
    "df_results_by_within_session_test_number = df_results.pivot_table(\n",
    "index = 'Test_#_Within_Session', values = ['WPM', 'Count'], \n",
    "aggfunc = {'WPM':'mean', 'Count':'sum'}).reset_index()\n",
    "df_results_by_within_session_test_number.query(\"Count >= 10\", inplace = True)\n",
    "# The above line prevents rows with low counts from skewing the results.\n",
    "df_results_by_within_session_test_number.to_csv(\n",
    "'Analyses/results_by_within_session_test_number.csv', index = False)\n",
    "df_results_by_within_session_test_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_results_by_within_session_test_number) > 0: # The player might not\n",
    "    # yet have completed more than 10 sessions, in which case the following\n",
    "    # code should be skipped (as there wouldn't be anything to graph).\n",
    "    fig_wpm_by_within_session_test_number = px.line(\n",
    "    df_results_by_within_session_test_number, \n",
    "    x = 'Test_#_Within_Session', y = 'WPM',\n",
    "    title = 'Average WPM by Within-Session Test Number<br><sub><i>Note: Only \\\n",
    "sessions with at least 10 tests are included in this chart.')\n",
    "    fig_wpm_by_within_session_test_number.update_layout(\n",
    "    xaxis_title = 'Within-Session Test Number')\n",
    "    fig_wpm_by_within_session_test_number.write_html(\n",
    "    'Analyses/wpm_by_within_session_test_number.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_wpm_by_within_session_test_number.write_image(\n",
    "        'Analyses/wpm_by_within_session_test_number.png', width = 1920, \n",
    "        height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_wpm_by_within_session_test_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_session = df_results['Session'].max()\n",
    "\n",
    "# The following chart plots the player's most recent sessions \n",
    "# on the same graph. This graph will\n",
    "# be quite 'busy,' but players can double-click a session number in order \n",
    "# to show results for only that session (which may be more useful).\n",
    "fig_session_results = px.line(\n",
    "df_results.query(\"Session >= @latest_session - 9\"), \n",
    "x = 'Test_#_Within_Session', y = 'WPM', color = 'Session',\n",
    "title = 'WPM by Within-Session Test Number for Last 10 Sessions')\n",
    "fig_session_results.update_layout(\n",
    "    xaxis_title = 'Within-Session Test Number')\n",
    "fig_session_results.write_html('Analyses/latest_session_results.html')\n",
    "if save_image_copies_of_charts == True:\n",
    "    fig_session_results.write_image(\n",
    "    'Analyses/latest_session_results.png', width = 1920, \n",
    "    height = 1080, engine = 'kaleido', scale = 2)\n",
    "fig_session_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating word-level analyses:\n",
    "\n",
    "Note: This section used to include code that would calculate the fastest single-word entry times. However, I found that these results could be distorted by computer lag. Specifically, if the player enters keys while the computer is frozen, some of those keypress durations will be reported as shorter than they actually were. (This makes sense, in that while the computer is frozen, the actual keypress time might not get logged; instead, a later post-freeze time will get logged. This post-freeze time will then be closer to the next keypress time, causing a shorter-than-actual keypress time to get reported.) (I simulated computer lag in my tests by entering a time.sleep() command, but I believe actual lag would produce similar errors). These skewed keypress durations can in turn skew the reported time needed to enter each word.\n",
    "\n",
    "Therefore, while the code still shows median word entry times (which are less susceptible to this issue), it will no longer calculate the fastest times that a particular word was entered. These can still be located within the word stats file, but the results should be interpreted with great caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll skip the word-level analyses section if we have no data to analyze.\n",
    "\n",
    "if len(df_word_stats) == 0:\n",
    "    run_word_analyses = 0\n",
    "else:\n",
    "    run_word_analyses = 1\n",
    "    print(\"Creating word-level analyses.\")\n",
    "\n",
    "run_word_analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_word_analyses == 1:\n",
    "    df_word_stats_pivot = df_word_stats.pivot_table(index = 'word', \n",
    "    values = {'Count', 'typed_word_without_mistakes', 'WPM'}, \n",
    "    aggfunc = {'Count':'sum', 'typed_word_without_mistakes':'mean', \n",
    "    'WPM':'median'}).reset_index().sort_values(\n",
    "    'WPM', ascending = False).reset_index(drop=True)\n",
    "    df_word_stats_pivot.rename(columns = {'WPM':'Median WPM', 'word':'Word',\n",
    "    'typed_word_without_mistakes':'Mistake-Free Entry Proportion'}, \n",
    "    inplace = True)\n",
    "    common_word_cutoff = 5 # This cutoff will be used to create variants\n",
    "    # of charts and tables that are limited to commonly typed words.\n",
    "    df_common_word_stats_pivot = df_word_stats_pivot.query(\n",
    "    \"Count >= @common_word_cutoff\").copy()\n",
    "    df_word_stats_pivot.to_csv('Analyses/word_stats_pivot.csv', index = False)\n",
    "    df_common_word_stats_pivot.to_csv('Analyses/word_stats_pivot_common.csv', \n",
    "    index = False)\n",
    "    df_word_stats_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_word_stats_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_word_analyses == 1:\n",
    "    fig_words_with_highest_median_wpms = px.bar(df_word_stats_pivot.head(100), \n",
    "    x = 'Word', y = 'Median WPM', color = 'Count', text_auto = '.6s',\n",
    "    title = 'Words With Highest Median WPMs')\n",
    "    fig_words_with_highest_median_wpms.write_html(\n",
    "    'Analyses/words_with_highest_median_wpms.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_words_with_highest_median_wpms.write_image(\n",
    "        'Analyses/words_with_highest_median_wpms.png', width = 1920, \n",
    "        height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_words_with_highest_median_wpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_word_analyses == 1) & (len(df_common_word_stats_pivot) >= 1):\n",
    "    fig_words_with_highest_median_wpms_common = px.bar(\n",
    "    df_common_word_stats_pivot.head(100), \n",
    "    x = 'Word', y = 'Median WPM', color = 'Count', text_auto = '.6s',\n",
    "    title = f'Words With Highest Median WPMs\\\n",
    "<br><sub><i>Note: this chart only includes words that have been typed at least \\\n",
    "{common_word_cutoff} times.</i></sub>')\n",
    "    fig_words_with_highest_median_wpms_common.write_html(\n",
    "    'Analyses/words_with_highest_median_wpms_common.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_words_with_highest_median_wpms_common.write_image(\n",
    "        'Analyses/words_with_highest_median_wpms_common.png', width = 1920, \n",
    "        height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_words_with_highest_median_wpms_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_word_analyses == 1:\n",
    "    fig_words_with_lowest_median_wpms = px.bar(\n",
    "    df_word_stats_pivot.sort_values(\n",
    "    'Median WPM').head(100), x = 'Word', y = 'Median WPM', color = 'Count', \n",
    "    text_auto = '.6s', title = 'Words With Lowest Median WPMs')\n",
    "    fig_words_with_lowest_median_wpms.write_html(\n",
    "    'Analyses/words_with_lowest_median_wpms.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_words_with_lowest_median_wpms.write_image(\n",
    "        'Analyses/words_with_lowest_median_wpms.png', width = 1920, \n",
    "        height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_words_with_lowest_median_wpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_word_analyses == 1) & (len(df_common_word_stats_pivot) >= 1):\n",
    "    fig_words_with_lowest_median_wpms_common = px.bar(\n",
    "    df_common_word_stats_pivot.sort_values('Median WPM').head(100), \n",
    "    x = 'Word', y = 'Median WPM', color = 'Count', text_auto = '.6s',\n",
    "    title = f'Words With Lowest Median WPMs\\\n",
    "<br><sub><i>Note: this chart only includes words that have been typed at least \\\n",
    "{common_word_cutoff} times.</i></sub>')\n",
    "    fig_words_with_lowest_median_wpms_common.write_html(\n",
    "    'Analyses/words_with_lowest_median_wpms_common.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_words_with_lowest_median_wpms_common.write_image(\n",
    "        'Analyses/words_with_lowest_median_wpms_common.png', width = 1920, \n",
    "        height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_words_with_lowest_median_wpms_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_word_stats_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating charts that show which commonly-typed words have the highest and lowest accuracy rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_word_analyses == 1) & (len(df_common_word_stats_pivot) >= 1):\n",
    "    fig_words_with_highest_accuracy_rates_common = px.bar(\n",
    "    df_common_word_stats_pivot.sort_values(\n",
    "    ['Mistake-Free Entry Proportion', 'Count'], ascending = False).head(100),\n",
    "    x = 'Word', y = 'Mistake-Free Entry Proportion', color = 'Count', \n",
    "    text_auto = '.2%',\n",
    "    title = f'Words With Highest Accuracy Rates\\\n",
    "<br><sub><i>Note: this chart only includes words that have been typed at least \\\n",
    "{common_word_cutoff} times.</i></sub>')\n",
    "    fig_words_with_highest_accuracy_rates_common.update_layout(\n",
    "    yaxis_tickformat = '.0%', yaxis_title = '% of Mistake-Free Entries')\n",
    "    fig_words_with_highest_accuracy_rates_common.write_html(\n",
    "    'Analyses/words_with_highest_accuracy_rates_common.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_words_with_highest_accuracy_rates_common.write_image(\n",
    "        'Analyses/words_with_highest_accuracy_rates_common.png', width = 1920, \n",
    "        height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_words_with_highest_accuracy_rates_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_word_analyses == 1) & (len(df_common_word_stats_pivot) >= 1):\n",
    "    fig_words_with_lowest_accuracy_rates_common = px.bar(\n",
    "    df_common_word_stats_pivot.sort_values(\n",
    "    ['Mistake-Free Entry Proportion', 'Count'], \n",
    "    ascending = [True, False]).head(100),\n",
    "    x = 'Word', y = 'Mistake-Free Entry Proportion', color = 'Count', \n",
    "    text_auto = '.2%',\n",
    "    title = f'Words With Lowest Accuracy Rates\\\n",
    "<br><sub><i>Note: this chart only includes words that have been typed at least \\\n",
    "{common_word_cutoff} times.</i></sub>')\n",
    "    fig_words_with_lowest_accuracy_rates_common.update_layout(\n",
    "    yaxis_tickformat = '.0%', yaxis_title = '% of Mistake-Free Entries')\n",
    "    fig_words_with_lowest_accuracy_rates_common.write_html(\n",
    "    'Analyses/words_with_lowest_accuracy_rates_common.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_words_with_lowest_accuracy_rates_common.write_image(\n",
    "        'Analyses/words_with_lowest_accuracy_rates_common.png', width = 1920, \n",
    "        height = 1080, engine = 'kaleido', scale = 2)\n",
    "    fig_words_with_lowest_accuracy_rates_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script used to show the highest-ever WPMs for individual words, but this code has been removed due to accuracy issues caused by computer lag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing results by setting characteristics:\n",
    "\n",
    "This section will show how players' results differ based on various elements of their settings, such as their locations, keyboards, and keyboard layouts. (Players provide this setting-related information during the beginning of each game session. It's entirely optional, so if no data are available for a given characteristic, the visualization code for that data will get skipped.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results_by_setting_component(component, metric):\n",
    "    '''This function compares players' results for a particular metric (e.g.\n",
    "    WPM or Extra Keystrokes %) by a particular element of their setting, such as\n",
    "    their location or keyboard. This code was moved to a function in order to \n",
    "    simplify the program.\n",
    "    \n",
    "    component: The component to analyze. This must be a column within\n",
    "    df_results ('Keyboard', 'Location', etc.)\n",
    "    metric: The outcome variable to analyze, such as 'WPM' or 'Extra Keystrokes %'.\n",
    "    It too must be a column within df_results.'''\n",
    "\n",
    "    # Filtering the DataFrame to include only rows with valid results\n",
    "    # for the chosen metric-component pair:\n",
    "    df_component_metric_results = df_results.query(\n",
    "    f\"`{component}` == `{component}` & `{metric}` == `{metric}`\").copy()\n",
    "    # The backticks were added in so that field names with spaces\n",
    "    # (such as 'Extra Keystrokes %') could also be made compatible with \n",
    "    # query(). \n",
    "    # NaN won't equal NaN, so this query() statement will filter out\n",
    "    # results with NaN values for either the component or the metric.\n",
    "    # (This ingenious means of filtering NaN values comes from StackOverflow\n",
    "    # user DSM: https://stackoverflow.com/a/26535881/13097194)\n",
    "    # If we don't have any data on the selected metric for the chosen \n",
    "    # component, we'll want to skip these analyses.\n",
    "    if len(df_component_metric_results) > 0:\n",
    "        df_setting_comparison = df_component_metric_results.pivot_table(\n",
    "        index = component, \n",
    "        values = [metric, 'Count'], aggfunc = \n",
    "        {metric:'mean', 'Count':'sum'}).sort_values(\n",
    "        metric, ascending = False).reset_index() # Note the use of query()\n",
    "        # to exclude empty-string location values from the pivot table\n",
    "        df_setting_comparison.rename(columns = {'Count':'Number of Tests'}, \n",
    "        inplace = True)\n",
    "        df_setting_comparison\n",
    "\n",
    "        fig_setting_comparison = px.bar(df_setting_comparison, x = component, \n",
    "        y = metric, color = 'Number of Tests', text_auto = '.6s', \n",
    "        title = f'Average {metric} by {component}')\n",
    "        fig_setting_comparison.update_layout(legend_title_text = 'Test Count')\n",
    "        fig_setting_comparison.write_html(\n",
    "        f'Analyses/{metric}_by_{component.lower()}.html')\n",
    "        if save_image_copies_of_charts == True:\n",
    "            fig_setting_comparison.write_image(\n",
    "            f'Analyses/{metric}_by_{component.lower()}.png', \n",
    "            width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "        return fig_setting_comparison\n",
    "    else:\n",
    "        print(f\"Data on {metric} by {component} \\\n",
    "is not yet avialable, so charts that rely on it will not be created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running analyze_results_by_setting_component for different components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in ['Location', 'Keyboard', 'Layout', 'Caffeine', 'Custom_1', 'Custom_2', 'Custom_3', 'Autostart']:\n",
    "    analyze_results_by_setting_component(component, 'WPM')\n",
    "    analyze_results_by_setting_component(component, 'Extra Keystrokes %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the following code is a modified version of the create_pivot_for_charts() function found in my [Dash School Dashboard project](https://github.com/kburchfiel/dash_school_dashboard/blob/main/dsd/app_functions_and_variables.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results_by_multiple_setting_components(\n",
    "    original_data_source, y_value, comparison_values, pivot_aggfunc):\n",
    "    '''This function turns the DataFrame passed to original_data_source\n",
    "    into a pivot table that can serve as the basis for a Plotly chart. \n",
    "    original_data_source: The source of the data that will be graphed.\n",
    "\n",
    "    y_value: The y value to use within the graph.\n",
    "\n",
    "    comparison_values: A list of values that will be used to pivot the\n",
    "    DataFrame. These values help determine the level of detail shown in the\n",
    "    final bar chart. \n",
    "\n",
    "    pivot_aggfunc: The aggregate function ('mean', 'sum', 'count', etc.) \n",
    "    to be passed to the pivot_table() call.'''\n",
    "\n",
    "    data_source = original_data_source.copy()\n",
    "\n",
    "    # Removing results with NaN values for a given comparison value\n",
    "    # so that they won't get incorporated into the pivot table and chart:\n",
    "    for value in comparison_values:\n",
    "        data_source.query(f\"`{value}` == `{value}`\", inplace = True)\n",
    "    # Also removing results with missing y_value data:\n",
    "        data_source.query(f\"`{y_value}` == `{y_value}`\", inplace = True)\n",
    "        if len(data_source) == 0:\n",
    "            # In this case, we don't have any data for the selected\n",
    "            # variable, so we won't be able to create a graph. The function\n",
    "            # will thus return nothing.\n",
    "            print(f\"Comparison data is not yet available for the {value} \\\n",
    "setting component, so charts that rely on it will not be created.\")\n",
    "            return \n",
    "    \n",
    "    # In order to show comparisons within the final graph, we need to create\n",
    "    # a table that contains those various comparisons. This function does so\n",
    "    # using the pivot_table() function within Pandas. The resulting pivot\n",
    "    # table will have one row for each comparison combination (as long as\n",
    "    # y value data were present for that combination.)\n",
    "\n",
    "    # The comparison_values\n",
    "    # variable will be used as the index for the pivot_table() function. \n",
    "    data_source_pivot = data_source.pivot_table(\n",
    "    index = comparison_values, values = [y_value, 'Count'], \n",
    "    aggfunc = {y_value:pivot_aggfunc,'Count':'sum'}).reset_index()\n",
    "    data_source_pivot.rename(columns = {'Count':'Number of Tests'}, \n",
    "    inplace = True)\n",
    "    # Next, we need to create x values that reflect the different column\n",
    "    # values in each row of the pivot table. These x values will then \n",
    "    # get passed to the graphing function.\n",
    "    # The following lines accomplish this by creating a new \n",
    "    # data_source_pivot column that contains strings made up of the \n",
    "    # values of each of the columns (other than the y value column) \n",
    "    # present in the bar chart. The chart will use these strings as \n",
    "    # x values when creating the grouped chart. \n",
    "\n",
    "    data_descriptor_values = comparison_values.copy()\n",
    "\n",
    "    data_descriptor = data_source_pivot[\n",
    "        data_descriptor_values[0]].copy().astype('str') # This line \n",
    "    # initializes data_descriptor as the first item within \n",
    "    # data_descriptor_values. copy() is needed in order to avoid \n",
    "    # modifying this column when the group column gets chosen.\n",
    "\n",
    "    # The following for loop iterates through each column name (except\n",
    "    # for the initial column, which has already been added\n",
    "    # to data_descriptor) in order to add all of the values present in \n",
    "    # data_descriptor_values to data_descriptor.\n",
    "    # The use of a for loop allows this code to adapt to different variable\n",
    "    # choices and different column counts.\n",
    "    for i in range(1, len(data_descriptor_values)):\n",
    "        data_descriptor += '/' + data_source_pivot[\n",
    "            data_descriptor_values[i]].astype('str') # This line adds \n",
    "            # the value of a given column to data_descriptor.\n",
    "\n",
    "    data_source_pivot['Group'] = data_descriptor # This group column will be \n",
    "    # used as the x value of the chart.\n",
    "\n",
    "    data_source_pivot.sort_values(y_value, ascending = False, inplace = True)\n",
    "\n",
    "    # Creating a title that includes each comparison:\n",
    "    chart_title = f'Average {y_value} by ' + '/'.join(comparison_values)\n",
    "\n",
    "    fig_results = px.bar(data_source_pivot, x = 'Group', \n",
    "    y = y_value, color = 'Number of Tests', text_auto='.6s',\n",
    "    title = chart_title)\n",
    "\n",
    "    fig_results.update_layout(legend_title_text = 'Test Count')\n",
    "    \n",
    "    # Creating a filename that incorporates lowercase versions of each \n",
    "    # comparison option:\n",
    "    chart_filename = f'Analyses/{y_value}_by_'+'_'.join(\n",
    "    [value.lower() for value in comparison_values])\n",
    "    fig_results.write_html(chart_filename+'.html')\n",
    "    if save_image_copies_of_charts == True:\n",
    "        fig_results.write_image(\n",
    "        chart_filename+'.png', \n",
    "        width = 1920, height = 1080, engine = 'kaleido', scale = 2)\n",
    "\n",
    "    return fig_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling this function for both WPM and Extra Keystrokes % metrics for selected comparison groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comparison_value_set in [['Location', 'Keyboard'], \n",
    "    ['Location', 'Autostart'],\n",
    "    ['Keyboard', 'Autostart'],\n",
    "    ['Location', 'Keyboard', 'Autostart']]:\n",
    "    for y_value in ['WPM', 'Extra Keystrokes %']:\n",
    "        analyze_results_by_multiple_setting_components(original_data_source = df_results,\n",
    "        y_value = y_value, comparison_values = comparison_value_set, pivot_aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_end_time = time.time()\n",
    "analysis_time = analysis_end_time - analysis_start_time\n",
    "print(f\"Finished updating analyses in {round(analysis_time, 3)} seconds. \\\n",
    "Press Enter to Exit.\") # Allows the console to stay open when the\n",
    "# .py version of the program is run\n",
    "\n",
    "input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ga15pyd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
